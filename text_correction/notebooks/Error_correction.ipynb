{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Error_correction.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.9"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "cellView": "both",
        "id": "MvEblsgEXxrd"
      },
      "source": [
        "%tensorflow_version 1.x"
      ],
      "execution_count": 52,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9hih0Sx6_LZR"
      },
      "source": [
        "import os\n",
        "import numpy as np\n",
        "import random\n",
        "import re\n",
        "import string\n",
        "import tensorflow as tf\n",
        "import zipfile\n",
        "import pickle\n",
        "import matplotlib.pyplot as plt"
      ],
      "execution_count": 53,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9K72xmdhE5X6",
        "outputId": "b2ca5d37-e6c4-4ed7-90c3-947ada200659"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')\n",
        "path_to_dataset = '/content/gdrive/My Drive/IR/icdar2019'"
      ],
      "execution_count": 54,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/gdrive; to attempt to forcibly remount, call drive.mount(\"/content/gdrive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "cellView": "both",
        "id": "Mvf09fjugFU_"
      },
      "source": [
        "def create_pairs(file, start=0):\n",
        "    \"\"\"\n",
        "    Create sentence pairs, where first sentence is the OCR-ed sentence and \n",
        "    2nd sentence is the GS sentence or the target one. This can be viewed as Machine Translation\n",
        "    task.\n",
        "    \"\"\"\n",
        "    print(\"Reading lines...\")\n",
        "\n",
        "    with open(file) as f:\n",
        "        data = f.readlines()\n",
        "\n",
        "    clean_sentences_ocr = []\n",
        "    clean_sentences_gs = []\n",
        "\n",
        "    for i in range(start, len(data), 2):\n",
        "      clean_sentences_ocr.append(clean_text(data[i]))\n",
        "      clean_sentences_gs.append(clean_text(data[i + 1]))\n",
        "\n",
        "    pairs = [[x, y] for x, y in zip(clean_sentences_ocr, clean_sentences_gs)]\n",
        "\n",
        "    return pairs"
      ],
      "execution_count": 55,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TWmo6RbgFl2b"
      },
      "source": [
        "def clean_text(text):\n",
        "    text = re.sub(r'\\n', '', text)\n",
        "\n",
        "    return text.lower()"
      ],
      "execution_count": 56,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tcAlSAyoGI1A",
        "outputId": "edc93688-feb7-431c-a034-b3c7c0392507"
      },
      "source": [
        "def prepare_data(file):\n",
        "    return create_pairs(file)\n",
        "\n",
        "input_file = path_to_dataset + '/correct_single.txt'\n",
        "pairs = prepare_data(input_file)"
      ],
      "execution_count": 57,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Reading lines...\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "q3DuIZsKFR_T",
        "outputId": "6d6eea43-b16c-4dda-b0f7-2ea10bc11528"
      },
      "source": [
        "print(\"Read {} word pairs\".format(len(pairs) // 2))\n",
        "pair1 = random.choice(pairs)\n",
        "pair2 = random.choice(pairs)\n",
        "pair3 = random.choice(pairs)\n",
        "\n",
        "print(\"Pair 1: OCR: {}, GS: {}, len1: {} and len2: {}\".format(pair1[0], pair1[1], len(pair1[0]), len(pair1[1])))\n",
        "print(\"Pair 2: OCR: {}, GS: {}, len1: {} and len2: {}\".format(pair2[0], pair2[1], len(pair2[0]), len(pair2[1])))\n",
        "print(\"Pair 3: OCR: {}, GS: {}, len1: {} and len2: {}\".format(pair3[0], pair3[1], len(pair3[0]), len(pair3[1])))"
      ],
      "execution_count": 58,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Read 7122 word pairs\n",
            "Pair 1: OCR: отъ, GS: отъ, len1: 3 and len2: 3\n",
            "Pair 2: OCR: човър-, GS: човър‑, len1: 6 and len2: 6\n",
            "Pair 3: OCR: ,е, GS: @ѣ, len1: 2 and len2: 2\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ga2CYACE-ghb"
      },
      "source": [
        "Create a small validation set."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "cellView": "both",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "w-oBpfFG-j43",
        "outputId": "ed17a777-cf08-4a01-ca9a-152600a07b98"
      },
      "source": [
        "valid_size = 1000\n",
        "valid_pairs = pairs[:valid_size]\n",
        "train_pairs = pairs[valid_size:]\n",
        "\n",
        "train_size = len(train_pairs)\n",
        "print(train_size, train_pairs[:5])\n",
        "print(valid_size, valid_pairs[:5])"
      ],
      "execution_count": 59,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "13245 [['въренъ', 'вѣренъ'], ['бждн.', 'бѫди.'], ['унизи@', 'унизѝ'], ['с’', \"с'\"], ['измьна', 'измѣна']]\n",
            "1000 [['@@@350', '   350'], ['хриету', 'христу'], ['служители;', 'служитель;'], ['кръви', 'кръвь'], ['тьло', 'тѣло']]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HGC6SIFKIpXH",
        "outputId": "2f5986dc-580f-4132-ec63-363c092e8b17"
      },
      "source": [
        "content = ''.join([p[0] + p[1] for p in pairs])\n",
        "\n",
        "invalid_chars = set(['^', '■', '•', '~', '§', '°', '®', '&', ' ', '½', 'λ', '„', '«'])\n",
        "all_chars = set(content) - invalid_chars\n",
        "\n",
        "all_chars = list(all_chars)\n",
        "print(all_chars)\n",
        "print(\"All chars are: {}\".format(len(all_chars)))"
      ],
      "execution_count": 60,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[\"'\", '!', ']', '<', ',', '2', 'h', '.', 'л', 'р', '8', '|', '‐', '5', 'ѣ', 'м', 'у', '6', ')', 'l', '@', '‑', 'o', '0', '}', 'к', 'ц', 'm', 'ч', 'n', 'a', '[', '%', 'ῳ', '‘', '—', '’', 'б', '?', 'ю', 't', '3', 'в', 'и', 'ъ', 'я', 'г', 'п', 'γ', 'і', 'н', 'ῷ', 'z', 'j', '1', '―', 'b', 'ж', '̀', '“', ':', 'о', 'g', '\\\\', 'ӏ', '{', 'х', 'v', 'ӣ', '(', 'д', '\"', 'τ', 'f', 'd', 'й', '>', '9', 'u', '”', 'ό', 's', 'ѫ', 'p', ';', '*', '7', 'i', '/', '4', 'т', 'x', '́', 'щ', '-', 'а', 'ѭ', 'с', '#', 'e', 'k', 'ы', 'ь', 'ш', 'з', 'ф', '»', 'c', 'r', 'е']\n",
            "All chars are: 110\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "cellView": "both",
        "id": "KyVd8FxT5QBc"
      },
      "source": [
        "def logprob(predictions, labels):\n",
        "    \"\"\"Log-probability of the true labels in a predicted batch.\"\"\"\n",
        "    predictions[predictions < 1e-10] = 1e-10\n",
        "    return np.sum(np.multiply(labels, -np.log(predictions))) / labels.shape[0]\n",
        "\n",
        "def sample_distribution(distribution):\n",
        "    \"\"\"Sample one element from a distribution assumed to be an array of normalized probabilities.\n",
        "    \"\"\"\n",
        "    r = random.uniform(0, 1)\n",
        "    s = 0\n",
        "    for i in range(len(distribution)):\n",
        "        s += distribution[i]\n",
        "        if s >= r:\n",
        "            return i\n",
        "    \n",
        "    return len(distribution) - 1\n",
        "\n",
        "def sample(prediction):\n",
        "    \"\"\"Turn a prediction into a 1-hot encoded vecotr.\"\"\"\n",
        "    p = np.zeros(shape=[1, vocabulary_size], dtype=np.float)\n",
        "    p[0, sample_distribution(prediction[0])] = 1.0\n",
        "\n",
        "    return p\n",
        "\n",
        "def random_distribution():\n",
        "    \"\"\"Generate a random column of probabilities.\"\"\"\n",
        "    b = np.random.uniform(0.0, 1.0, size=[1, vocabulary_size])\n",
        "    return b / np.sum(b, 1)[:, None]"
      ],
      "execution_count": 61,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "s1ihlV2t-KBI"
      },
      "source": [
        "from tensorflow.python.layers.core import Dense\n",
        "\n",
        "batch_size = 128\n",
        "rnn_size = 64\n",
        "num_layers = 2\n",
        "embedding_size = 64\n",
        "learning_rate = 0.001\n",
        "sequence_length = 10"
      ],
      "execution_count": 62,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bcqZXTcf2JyJ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1ed1d99d-cc6e-4daf-e5b5-d2c5701ba79a"
      },
      "source": [
        "print(\"Training pairs {}\".format(len(train_pairs) // 2))\n",
        "print(\"Validation pairs {}\".format(len(valid_pairs) // 2))"
      ],
      "execution_count": 63,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training pairs 6622\n",
            "Validation pairs 500\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "E91WkI-K-KBI",
        "outputId": "1f479a41-a7a1-4e10-806d-44eb172692dc"
      },
      "source": [
        "def create_dictionaries():\n",
        "    special_words = ['<PAD>', '<UNK>', '<GO>',  '<END>']\n",
        "\n",
        "    words = all_chars + special_words\n",
        "    dictionary = {word: i for i, word in enumerate(words)}\n",
        "\n",
        "    return dictionary, dict(zip(dictionary.values(), dictionary.keys())) \n",
        "\n",
        "dictionary, reverse_dictionary = create_dictionaries()\n",
        "\n",
        "print(dictionary)\n",
        "print(reverse_dictionary)\n",
        "\n",
        "x_sentences = [pair[0] for pair in train_pairs]\n",
        "y_sentences = [pair[1] for pair in train_pairs]\n",
        "\n",
        "# Convert each word to dictionary representations\n",
        "x_ids = [[dictionary.get(letter, dictionary['<UNK>']) for letter in sentence] for sentence in x_sentences]\n",
        "y_ids = [[dictionary.get(letter, dictionary['<UNK>']) for letter in sentence] for sentence in y_sentences]\n",
        "\n",
        "print(\"Example raw data:\")\n",
        "print(train_pairs[:5])\n",
        "print(\"Example sequence\")\n",
        "print(x_ids[:5])\n",
        "print(\"\\n\")\n",
        "print(\"Example output\")\n",
        "print(y_ids[:5])"
      ],
      "execution_count": 64,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{\"'\": 0, '!': 1, ']': 2, '<': 3, ',': 4, '2': 5, 'h': 6, '.': 7, 'л': 8, 'р': 9, '8': 10, '|': 11, '‐': 12, '5': 13, 'ѣ': 14, 'м': 15, 'у': 16, '6': 17, ')': 18, 'l': 19, '@': 20, '‑': 21, 'o': 22, '0': 23, '}': 24, 'к': 25, 'ц': 26, 'm': 27, 'ч': 28, 'n': 29, 'a': 30, '[': 31, '%': 32, 'ῳ': 33, '‘': 34, '—': 35, '’': 36, 'б': 37, '?': 38, 'ю': 39, 't': 40, '3': 41, 'в': 42, 'и': 43, 'ъ': 44, 'я': 45, 'г': 46, 'п': 47, 'γ': 48, 'і': 49, 'н': 50, 'ῷ': 51, 'z': 52, 'j': 53, '1': 54, '―': 55, 'b': 56, 'ж': 57, '̀': 58, '“': 59, ':': 60, 'о': 61, 'g': 62, '\\\\': 63, 'ӏ': 64, '{': 65, 'х': 66, 'v': 67, 'ӣ': 68, '(': 69, 'д': 70, '\"': 71, 'τ': 72, 'f': 73, 'd': 74, 'й': 75, '>': 76, '9': 77, 'u': 78, '”': 79, 'ό': 80, 's': 81, 'ѫ': 82, 'p': 83, ';': 84, '*': 85, '7': 86, 'i': 87, '/': 88, '4': 89, 'т': 90, 'x': 91, '́': 92, 'щ': 93, '-': 94, 'а': 95, 'ѭ': 96, 'с': 97, '#': 98, 'e': 99, 'k': 100, 'ы': 101, 'ь': 102, 'ш': 103, 'з': 104, 'ф': 105, '»': 106, 'c': 107, 'r': 108, 'е': 109, '<PAD>': 110, '<UNK>': 111, '<GO>': 112, '<END>': 113}\n",
            "{0: \"'\", 1: '!', 2: ']', 3: '<', 4: ',', 5: '2', 6: 'h', 7: '.', 8: 'л', 9: 'р', 10: '8', 11: '|', 12: '‐', 13: '5', 14: 'ѣ', 15: 'м', 16: 'у', 17: '6', 18: ')', 19: 'l', 20: '@', 21: '‑', 22: 'o', 23: '0', 24: '}', 25: 'к', 26: 'ц', 27: 'm', 28: 'ч', 29: 'n', 30: 'a', 31: '[', 32: '%', 33: 'ῳ', 34: '‘', 35: '—', 36: '’', 37: 'б', 38: '?', 39: 'ю', 40: 't', 41: '3', 42: 'в', 43: 'и', 44: 'ъ', 45: 'я', 46: 'г', 47: 'п', 48: 'γ', 49: 'і', 50: 'н', 51: 'ῷ', 52: 'z', 53: 'j', 54: '1', 55: '―', 56: 'b', 57: 'ж', 58: '̀', 59: '“', 60: ':', 61: 'о', 62: 'g', 63: '\\\\', 64: 'ӏ', 65: '{', 66: 'х', 67: 'v', 68: 'ӣ', 69: '(', 70: 'д', 71: '\"', 72: 'τ', 73: 'f', 74: 'd', 75: 'й', 76: '>', 77: '9', 78: 'u', 79: '”', 80: 'ό', 81: 's', 82: 'ѫ', 83: 'p', 84: ';', 85: '*', 86: '7', 87: 'i', 88: '/', 89: '4', 90: 'т', 91: 'x', 92: '́', 93: 'щ', 94: '-', 95: 'а', 96: 'ѭ', 97: 'с', 98: '#', 99: 'e', 100: 'k', 101: 'ы', 102: 'ь', 103: 'ш', 104: 'з', 105: 'ф', 106: '»', 107: 'c', 108: 'r', 109: 'е', 110: '<PAD>', 111: '<UNK>', 112: '<GO>', 113: '<END>'}\n",
            "Example raw data:\n",
            "[['въренъ', 'вѣренъ'], ['бждн.', 'бѫди.'], ['унизи@', 'унизѝ'], ['с’', \"с'\"], ['измьна', 'измѣна']]\n",
            "Example sequence\n",
            "[[42, 44, 9, 109, 50, 44], [37, 57, 70, 50, 7], [16, 50, 43, 104, 43, 20], [97, 36], [43, 104, 15, 102, 50, 95]]\n",
            "\n",
            "\n",
            "Example output\n",
            "[[42, 14, 9, 109, 50, 44], [37, 82, 70, 43, 7], [16, 50, 43, 104, 43, 58], [97, 0], [43, 104, 15, 14, 50, 95]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nIO2ibct-KBI"
      },
      "source": [
        "def create_cell(rnn_size):\n",
        "    cell = tf.contrib.rnn.LSTMCell(rnn_size,initializer=tf.random_uniform_initializer(-0.1, 0.1, seed=2))\n",
        "    \n",
        "    return cell"
      ],
      "execution_count": 65,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7hx4w-tU-KBI"
      },
      "source": [
        "def get_model_inputs():\n",
        "    inputs = tf.placeholder(tf.int32, [batch_size, None], name = 'inputs')\n",
        "    labels = tf.placeholder(tf.int32, [batch_size, None])\n",
        "    lr = tf.placeholder(tf.float32)\n",
        "\n",
        "    input_sequence_length = tf.placeholder(tf.int32, (batch_size,), name = 'input_sequence_length')\n",
        "    label_sequence_length = tf.placeholder(tf.int32, (batch_size,), name = 'label_sequence_length')\n",
        "    \n",
        "    max_label_sequence_length = tf.reduce_max(label_sequence_length)\n",
        "    \n",
        "    return inputs, labels, lr, input_sequence_length, label_sequence_length, max_label_sequence_length"
      ],
      "execution_count": 66,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3SnYtrJ1-KBI"
      },
      "source": [
        "def encoding_layer(inputs, rnn_size, num_layers, input_sequence_length, vocab_size, embedding_size):\n",
        "\n",
        "    embedded_input = tf.contrib.layers.embed_sequence(inputs, vocab_size, embedding_size)\n",
        "    encoder_cell = tf.contrib.rnn.MultiRNNCell([create_cell(rnn_size) for _ in range(num_layers)])\n",
        "    encoder_output, encoder_state = tf.nn.dynamic_rnn(encoder_cell, embedded_input, sequence_length=input_sequence_length, dtype=tf.float32)\n",
        "    \n",
        "    return encoder_output, encoder_state"
      ],
      "execution_count": 67,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fSCshWvK-KBI"
      },
      "source": [
        "# Some basic preprocessing to remove the last char and add the GO symbol for the decoder\n",
        "def process_decoder_input(labels, dictionary, batch_size):\n",
        "    ending = tf.strided_slice(labels, [0, 0], [batch_size, -1], [1, 1])\n",
        "    decoder_input = tf.concat([tf.fill([batch_size, 1], dictionary['<GO>']), ending], 1)\n",
        "\n",
        "    return decoder_input"
      ],
      "execution_count": 68,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SSHtZ0bK-KBI"
      },
      "source": [
        "def decoding_layer(dictionary, embedding_size, num_layers, rnn_size, labels_sequence_length, max_label_sequence_length, encoder_state, decoder_input):\n",
        "\n",
        "    vocab_size = len(dictionary)\n",
        "    decoder_embeddings = tf.Variable(tf.random_uniform([vocab_size, embedding_size]))\n",
        "    decoder_embed_input = tf.nn.embedding_lookup(decoder_embeddings, decoder_input)\n",
        "\n",
        "    decoder_cell = tf.contrib.rnn.MultiRNNCell([create_cell(rnn_size) for _ in range(num_layers)])\n",
        "     \n",
        "    output_layer = Dense(vocab_size, kernel_initializer=tf.truncated_normal_initializer(mean = 0.0, stddev=0.1))\n",
        "\n",
        "    with tf.variable_scope(\"decode\"):\n",
        "        training_helper = tf.contrib.seq2seq.TrainingHelper(inputs=decoder_embed_input, sequence_length=labels_sequence_length, time_major=False)\n",
        "        training_decoder = tf.contrib.seq2seq.BasicDecoder(decoder_cell, training_helper, encoder_state, output_layer) \n",
        "        training_decoder_output = tf.contrib.seq2seq.dynamic_decode(training_decoder,impute_finished=True, maximum_iterations=max_label_sequence_length)[0]\n",
        "\n",
        "    with tf.variable_scope(\"decode\", reuse=True):\n",
        "        start_tokens = tf.tile(tf.constant([dictionary['<GO>']], dtype=tf.int32), [batch_size], name='start_tokens')\n",
        "\n",
        "        inference_helper = tf.contrib.seq2seq.GreedyEmbeddingHelper(decoder_embeddings, start_tokens, dictionary['<END>'])\n",
        "        inference_decoder = tf.contrib.seq2seq.BasicDecoder(decoder_cell,inference_helper,encoder_state,output_layer)\n",
        "        inference_decoder_output = tf.contrib.seq2seq.dynamic_decode(inference_decoder, impute_finished=True, maximum_iterations=max_label_sequence_length)[0]\n",
        "    \n",
        "    return training_decoder_output, inference_decoder_output"
      ],
      "execution_count": 69,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qoqx-OjN-KBI"
      },
      "source": [
        "def seq2seq_model(input_data, labels, lr, inputs_sequence_length, labels_sequence_length, max_label_sequence_length, vocab_size, embedding_size, rnn_size, num_layers):\n",
        "    \n",
        "    _, encoder_state = encoding_layer(input_data, rnn_size, num_layers, inputs_sequence_length, vocab_size, embedding_size)\n",
        "    \n",
        "    decoder_input = process_decoder_input(labels, dictionary, batch_size)\n",
        "    \n",
        "    training_decoder_output, inference_decoder_output = decoding_layer(dictionary, embedding_size, num_layers, rnn_size, labels_sequence_length,\\\n",
        "                                                                       max_label_sequence_length, encoder_state, decoder_input) \n",
        "    \n",
        "    return training_decoder_output, inference_decoder_output"
      ],
      "execution_count": 70,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RnlkqYjv-KBJ"
      },
      "source": [
        "train_graph = tf.Graph()\n",
        "\n",
        "with train_graph.as_default():\n",
        "    \n",
        "    input_data, labels, lr, input_sequence_length, label_sequence_length, max_label_sequence_length = get_model_inputs()\n",
        "    \n",
        "    training_decoder_output, inference_decoder_output = seq2seq_model(input_data, labels, lr, input_sequence_length,label_sequence_length, max_label_sequence_length,\\\n",
        "                                                                      len(dictionary),embedding_size, rnn_size, num_layers)    \n",
        "\n",
        "    training_logits = tf.identity(training_decoder_output.rnn_output, 'logits')\n",
        "    inference_logits = tf.identity(inference_decoder_output.sample_id, name='predictions')\n",
        "    \n",
        "    masks = tf.sequence_mask(label_sequence_length, max_label_sequence_length, dtype=tf.float32, name='masks')\n",
        "\n",
        "    with tf.name_scope(\"optimization\"):\n",
        "\n",
        "        cost = tf.contrib.seq2seq.sequence_loss(training_logits, labels, masks)\n",
        "\n",
        "        optimizer = tf.train.AdamOptimizer(lr)\n",
        "\n",
        "        gradients = optimizer.compute_gradients(cost)\n",
        "        capped_gradients = [(tf.clip_by_value(grad, -5., 5.), var) for grad, var in gradients if grad is not None]\n",
        "        train_op = optimizer.apply_gradients(capped_gradients)"
      ],
      "execution_count": 71,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UhbYaaAi-KBJ"
      },
      "source": [
        "def pad_batch(batch, pad_int):\n",
        "    # make sure each word has the same length\n",
        "    max_length = max([len(word) for word in batch])\n",
        "    return [word + [pad_int] * (max_length - len(word)) for word in batch]"
      ],
      "execution_count": 72,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FH1QCFtu-KBJ"
      },
      "source": [
        "class BatchGenerator(object):\n",
        "    def __init__(self, labels, inputs, batch_size, input_pad_int, label_pad_int):\n",
        "        self._labels = labels\n",
        "        self._inputs = inputs\n",
        "        self._batch_size = batch_size\n",
        "        self._input_pad_int = input_pad_int\n",
        "        self._label_pad_int = label_pad_int\n",
        "        self._cursor = 0\n",
        "  \n",
        "    def next(self):\n",
        "        # Generates a single batch\n",
        "        start_i = self._cursor * self._batch_size\n",
        "        input_batch = self._inputs[start_i:start_i + self._batch_size]\n",
        "        label_batch = self._labels[start_i:start_i + self._batch_size]\n",
        "        pad_input_batch = np.array(pad_batch(input_batch, self._input_pad_int))\n",
        "        pad_label_batch = np.array(pad_batch(label_batch, self._label_pad_int))\n",
        "        \n",
        "        pad_label_lengths = []\n",
        "        for i in pad_label_batch:\n",
        "            pad_label_lengths.append(len(i))\n",
        "\n",
        "        pad_input_lengths = []\n",
        "        for i in pad_input_batch:\n",
        "            pad_input_lengths.append(len(i))\n",
        "            \n",
        "        self._cursor = self._cursor + 1\n",
        "        \n",
        "        return pad_label_batch, pad_input_batch, pad_label_lengths, pad_input_lengths"
      ],
      "execution_count": 73,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Vn60g7lL-KBJ",
        "outputId": "4b6b4f17-a6e2-4b64-e7e0-6f77d4f758ab"
      },
      "source": [
        "train_input = x_ids[batch_size:]\n",
        "train_labels = y_ids[batch_size:]\n",
        "\n",
        "valid_input = x_ids[:batch_size]\n",
        "valid_labels = y_ids[:batch_size]\n",
        "\n",
        "batch_generator_valid = BatchGenerator(valid_labels, valid_input, batch_size, dictionary['<PAD>'], dictionary['<PAD>'])\n",
        "batch_generator_train = BatchGenerator(train_labels, train_input, batch_size, dictionary['<PAD>'], dictionary['<PAD>'])\n",
        "\n",
        "\n",
        "(valid_labels_batch, valid_input_batch, valid_labels_lengths, valid_input_lengths) = batch_generator_valid.next()\n",
        "\n",
        "checkpoint = \"seq2seq.ckpt\"\n",
        "training_epochs = 100\n",
        "\n",
        "loss_train = []\n",
        "loss_valid = []\n",
        "\n",
        "data = []\n",
        "for batch_i in range(0, len(train_input) // batch_size):\n",
        "    data.append(batch_generator_train.next())\n",
        "\n",
        "\n",
        "with tf.Session(graph=train_graph) as sess:\n",
        "    sess.run(tf.global_variables_initializer())\n",
        "\n",
        "    for epoch in range(training_epochs):\n",
        "\n",
        "      for labels_batch, input_batch, labels_lengths, input_lengths in data:\n",
        "        _, loss = sess.run([train_op, cost],\n",
        "        {\n",
        "            input_data: input_batch,\n",
        "            labels: labels_batch,\n",
        "            lr: learning_rate,\n",
        "            label_sequence_length: labels_lengths,\n",
        "            input_sequence_length: input_lengths\n",
        "          })\n",
        "        \n",
        "      validation_loss = sess.run(\n",
        "      [cost],\n",
        "      {\n",
        "          input_data: valid_input_batch,\n",
        "          labels: valid_labels_batch,\n",
        "          lr: learning_rate,\n",
        "          label_sequence_length: valid_labels_lengths,\n",
        "          input_sequence_length: valid_input_lengths\n",
        "       })\n",
        "      \n",
        "      print('Epoch %d/%d - Loss: %.3f  - Validation loss: %.3f' % (epoch, training_epochs, loss, validation_loss[0]))\n",
        "      loss_train.append(loss)\n",
        "      loss_valid.append(validation_loss[0])\n",
        "\n",
        "    # save the model state\n",
        "    saver = tf.train.Saver()\n",
        "    saver.save(sess, checkpoint)\n",
        "    print('Model Trained and Saved')"
      ],
      "execution_count": 74,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 0/100 - Loss: 1.673  - Validation loss: 1.454\n",
            "Epoch 1/100 - Loss: 1.382  - Validation loss: 1.220\n",
            "Epoch 2/100 - Loss: 1.321  - Validation loss: 1.154\n",
            "Epoch 3/100 - Loss: 1.283  - Validation loss: 1.127\n",
            "Epoch 4/100 - Loss: 1.261  - Validation loss: 1.112\n",
            "Epoch 5/100 - Loss: 1.242  - Validation loss: 1.101\n",
            "Epoch 6/100 - Loss: 1.225  - Validation loss: 1.088\n",
            "Epoch 7/100 - Loss: 1.182  - Validation loss: 1.060\n",
            "Epoch 8/100 - Loss: 1.126  - Validation loss: 1.016\n",
            "Epoch 9/100 - Loss: 1.092  - Validation loss: 0.995\n",
            "Epoch 10/100 - Loss: 1.078  - Validation loss: 0.983\n",
            "Epoch 11/100 - Loss: 1.068  - Validation loss: 0.976\n",
            "Epoch 12/100 - Loss: 1.061  - Validation loss: 0.971\n",
            "Epoch 13/100 - Loss: 1.055  - Validation loss: 0.967\n",
            "Epoch 14/100 - Loss: 1.049  - Validation loss: 0.963\n",
            "Epoch 15/100 - Loss: 1.043  - Validation loss: 0.960\n",
            "Epoch 16/100 - Loss: 1.037  - Validation loss: 0.955\n",
            "Epoch 17/100 - Loss: 1.018  - Validation loss: 0.949\n",
            "Epoch 18/100 - Loss: 0.988  - Validation loss: 0.936\n",
            "Epoch 19/100 - Loss: 0.966  - Validation loss: 0.922\n",
            "Epoch 20/100 - Loss: 0.936  - Validation loss: 0.901\n",
            "Epoch 21/100 - Loss: 0.900  - Validation loss: 0.877\n",
            "Epoch 22/100 - Loss: 0.846  - Validation loss: 0.843\n",
            "Epoch 23/100 - Loss: 0.806  - Validation loss: 0.806\n",
            "Epoch 24/100 - Loss: 0.769  - Validation loss: 0.768\n",
            "Epoch 25/100 - Loss: 0.728  - Validation loss: 0.735\n",
            "Epoch 26/100 - Loss: 0.695  - Validation loss: 0.706\n",
            "Epoch 27/100 - Loss: 0.655  - Validation loss: 0.675\n",
            "Epoch 28/100 - Loss: 0.617  - Validation loss: 0.650\n",
            "Epoch 29/100 - Loss: 0.586  - Validation loss: 0.630\n",
            "Epoch 30/100 - Loss: 0.555  - Validation loss: 0.601\n",
            "Epoch 31/100 - Loss: 0.535  - Validation loss: 0.578\n",
            "Epoch 32/100 - Loss: 0.517  - Validation loss: 0.559\n",
            "Epoch 33/100 - Loss: 0.496  - Validation loss: 0.546\n",
            "Epoch 34/100 - Loss: 0.480  - Validation loss: 0.530\n",
            "Epoch 35/100 - Loss: 0.460  - Validation loss: 0.519\n",
            "Epoch 36/100 - Loss: 0.447  - Validation loss: 0.509\n",
            "Epoch 37/100 - Loss: 0.429  - Validation loss: 0.497\n",
            "Epoch 38/100 - Loss: 0.414  - Validation loss: 0.489\n",
            "Epoch 39/100 - Loss: 0.401  - Validation loss: 0.480\n",
            "Epoch 40/100 - Loss: 0.390  - Validation loss: 0.477\n",
            "Epoch 41/100 - Loss: 0.377  - Validation loss: 0.462\n",
            "Epoch 42/100 - Loss: 0.366  - Validation loss: 0.457\n",
            "Epoch 43/100 - Loss: 0.356  - Validation loss: 0.450\n",
            "Epoch 44/100 - Loss: 0.348  - Validation loss: 0.444\n",
            "Epoch 45/100 - Loss: 0.338  - Validation loss: 0.439\n",
            "Epoch 46/100 - Loss: 0.328  - Validation loss: 0.431\n",
            "Epoch 47/100 - Loss: 0.321  - Validation loss: 0.423\n",
            "Epoch 48/100 - Loss: 0.313  - Validation loss: 0.416\n",
            "Epoch 49/100 - Loss: 0.305  - Validation loss: 0.411\n",
            "Epoch 50/100 - Loss: 0.299  - Validation loss: 0.406\n",
            "Epoch 51/100 - Loss: 0.299  - Validation loss: 0.405\n",
            "Epoch 52/100 - Loss: 0.298  - Validation loss: 0.401\n",
            "Epoch 53/100 - Loss: 0.288  - Validation loss: 0.394\n",
            "Epoch 54/100 - Loss: 0.278  - Validation loss: 0.388\n",
            "Epoch 55/100 - Loss: 0.270  - Validation loss: 0.382\n",
            "Epoch 56/100 - Loss: 0.262  - Validation loss: 0.375\n",
            "Epoch 57/100 - Loss: 0.258  - Validation loss: 0.371\n",
            "Epoch 58/100 - Loss: 0.256  - Validation loss: 0.368\n",
            "Epoch 59/100 - Loss: 0.252  - Validation loss: 0.365\n",
            "Epoch 60/100 - Loss: 0.250  - Validation loss: 0.361\n",
            "Epoch 61/100 - Loss: 0.243  - Validation loss: 0.358\n",
            "Epoch 62/100 - Loss: 0.241  - Validation loss: 0.357\n",
            "Epoch 63/100 - Loss: 0.236  - Validation loss: 0.357\n",
            "Epoch 64/100 - Loss: 0.230  - Validation loss: 0.356\n",
            "Epoch 65/100 - Loss: 0.222  - Validation loss: 0.352\n",
            "Epoch 66/100 - Loss: 0.218  - Validation loss: 0.353\n",
            "Epoch 67/100 - Loss: 0.212  - Validation loss: 0.349\n",
            "Epoch 68/100 - Loss: 0.207  - Validation loss: 0.343\n",
            "Epoch 69/100 - Loss: 0.206  - Validation loss: 0.339\n",
            "Epoch 70/100 - Loss: 0.205  - Validation loss: 0.341\n",
            "Epoch 71/100 - Loss: 0.198  - Validation loss: 0.338\n",
            "Epoch 72/100 - Loss: 0.190  - Validation loss: 0.336\n",
            "Epoch 73/100 - Loss: 0.188  - Validation loss: 0.329\n",
            "Epoch 74/100 - Loss: 0.184  - Validation loss: 0.328\n",
            "Epoch 75/100 - Loss: 0.182  - Validation loss: 0.328\n",
            "Epoch 76/100 - Loss: 0.179  - Validation loss: 0.327\n",
            "Epoch 77/100 - Loss: 0.174  - Validation loss: 0.325\n",
            "Epoch 78/100 - Loss: 0.175  - Validation loss: 0.332\n",
            "Epoch 79/100 - Loss: 0.174  - Validation loss: 0.324\n",
            "Epoch 80/100 - Loss: 0.171  - Validation loss: 0.325\n",
            "Epoch 81/100 - Loss: 0.168  - Validation loss: 0.324\n",
            "Epoch 82/100 - Loss: 0.162  - Validation loss: 0.322\n",
            "Epoch 83/100 - Loss: 0.162  - Validation loss: 0.318\n",
            "Epoch 84/100 - Loss: 0.160  - Validation loss: 0.319\n",
            "Epoch 85/100 - Loss: 0.156  - Validation loss: 0.317\n",
            "Epoch 86/100 - Loss: 0.157  - Validation loss: 0.325\n",
            "Epoch 87/100 - Loss: 0.147  - Validation loss: 0.319\n",
            "Epoch 88/100 - Loss: 0.144  - Validation loss: 0.325\n",
            "Epoch 89/100 - Loss: 0.144  - Validation loss: 0.325\n",
            "Epoch 90/100 - Loss: 0.145  - Validation loss: 0.327\n",
            "Epoch 91/100 - Loss: 0.144  - Validation loss: 0.331\n",
            "Epoch 92/100 - Loss: 0.146  - Validation loss: 0.340\n",
            "Epoch 93/100 - Loss: 0.143  - Validation loss: 0.337\n",
            "Epoch 94/100 - Loss: 0.138  - Validation loss: 0.327\n",
            "Epoch 95/100 - Loss: 0.135  - Validation loss: 0.330\n",
            "Epoch 96/100 - Loss: 0.129  - Validation loss: 0.328\n",
            "Epoch 97/100 - Loss: 0.128  - Validation loss: 0.331\n",
            "Epoch 98/100 - Loss: 0.129  - Validation loss: 0.335\n",
            "Epoch 99/100 - Loss: 0.127  - Validation loss: 0.338\n",
            "Model Trained and Saved\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zoSEasTUcvWt"
      },
      "source": [
        "saved_model_path = path_to_dataset + '/seq2seq/'"
      ],
      "execution_count": 75,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 296
        },
        "id": "ysbpdwiPoDZ9",
        "outputId": "398adae1-2339-4f5f-ffcd-f1f6ff676fce"
      },
      "source": [
        "plt.plot(loss_train, label='training loss')\n",
        "plt.plot(loss_valid, label='validation loss')\n",
        "plt.xlabel(\"Epoch\")\n",
        "plt.ylabel(\"Loss\")\n",
        "plt.legend()"
      ],
      "execution_count": 76,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.legend.Legend at 0x7fcb16f93ed0>"
            ]
          },
          "metadata": {},
          "execution_count": 76
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YY7FWYq0dnDS"
      },
      "source": [
        "# with open('dictionary.pickle', 'wb') as handle:\n",
        "#     pickle.dump(dictionary, handle, protocol=pickle.HIGHEST_PROTOCOL)\n",
        "\n",
        "# with open('reverse_dictionary.pickle', 'wb') as handle:\n",
        "#     pickle.dump(reverse_dictionary, handle, protocol=pickle.HIGHEST_PROTOCOL)"
      ],
      "execution_count": 77,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6Bz93atBdgpM"
      },
      "source": [
        "with open(saved_model_path + 'dictionary.pickle', 'rb') as handle:\n",
        "    dictionary = pickle.load(handle)\n",
        "\n",
        "with open(saved_model_path + 'reverse_dictionary.pickle', 'rb') as handle:\n",
        "    reverse_dictionary = pickle.load(handle)"
      ],
      "execution_count": 78,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Kd4xzYhId1_L",
        "outputId": "839cc69b-6c44-46c8-bf51-d0c5f525f20d"
      },
      "source": [
        "print(dictionary)"
      ],
      "execution_count": 79,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'[': 0, '“': 1, 'f': 2, '*': 3, '#': 4, 'ц': 5, '?': 6, '”': 7, \"'\": 8, ',': 9, '»': 10, '\"': 11, '9': 12, '‑': 13, '@': 14, '<': 15, 'с': 16, 'c': 17, 'о': 18, 'л': 19, 'п': 20, 'б': 21, 'e': 22, 'ш': 23, 'і': 24, '—': 25, 'ж': 26, ';': 27, 'е': 28, '|': 29, '̀': 30, 'r': 31, 'h': 32, 'o': 33, '1': 34, '5': 35, '3': 36, 's': 37, 'у': 38, '’': 39, 'g': 40, '―': 41, 'τ': 42, '!': 43, '>': 44, '{': 45, 'j': 46, 'ъ': 47, 'х': 48, '6': 49, 'ѭ': 50, 'ῳ': 51, 'a': 52, 'г': 53, 'к': 54, 'x': 55, ':': 56, 'ы': 57, 't': 58, 'н': 59, '́': 60, '4': 61, 'м': 62, 'з': 63, 'ь': 64, 'l': 65, 'k': 66, ']': 67, 'z': 68, 'в': 69, '\\\\': 70, 'ῷ': 71, 'и': 72, 'ό': 73, 'ӏ': 74, '‐': 75, '(': 76, 'щ': 77, 'i': 78, '‘': 79, 'p': 80, 'т': 81, 'а': 82, 'ф': 83, 'd': 84, '.': 85, 'n': 86, '2': 87, '/': 88, 'm': 89, 'ӣ': 90, '8': 91, 'ю': 92, 'ѫ': 93, 'р': 94, '-': 95, '0': 96, '7': 97, 'я': 98, '}': 99, ')': 100, 'γ': 101, 'й': 102, 'ѣ': 103, 'v': 104, '%': 105, 'b': 106, 'ч': 107, 'u': 108, 'д': 109, '<PAD>': 110, '<UNK>': 111, '<GO>': 112, '<END>': 113}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-F9lXSIp-KBJ"
      },
      "source": [
        "def to_seq(text):\n",
        "    # preprocess text for the model\n",
        "    return [dictionary.get(word, dictionary['<UNK>']) for word in text] + [dictionary['<PAD>']]*(sequence_length-len(text))"
      ],
      "execution_count": 80,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HWZlV_qw-KBJ",
        "outputId": "2ab034bc-dae9-479b-fd9a-0b5c782b2786"
      },
      "source": [
        "pad = dictionary[\"<PAD>\"] \n",
        "\n",
        "checkpoint = path_to_dataset + '/seq2seq/seq2seq.ckpt'\n",
        "\n",
        "loaded_graph = tf.Graph()\n",
        "with tf.Session(graph=loaded_graph) as sess:\n",
        "    \n",
        "    # load the model\n",
        "    loader = tf.train.import_meta_graph(checkpoint + '.meta')\n",
        "    loader.restore(sess, checkpoint)\n",
        "\n",
        "    input_data = loaded_graph.get_tensor_by_name('inputs:0')\n",
        "    logits = loaded_graph.get_tensor_by_name('predictions:0')\n",
        "    input_sequence_length = loaded_graph.get_tensor_by_name('input_sequence_length:0')\n",
        "    label_sequence_length = loaded_graph.get_tensor_by_name('label_sequence_length:0')\n",
        "   \n",
        "    # words = ['когаго']\n",
        "    # words = ['когато']\n",
        "    # words = ['нещо']\n",
        "    # words = ['срЪдъ']\n",
        "    # words = ['погрешка']\n",
        "    # words = ['турилъ']\n",
        "    words = ['грешка']\n",
        "    # words = ['твърде']\n",
        "\n",
        "    input_sentence = ' '.join(words)\n",
        "    \n",
        "    print()\n",
        "    print('Original Text: %s' % input_sentence)\n",
        "    print('Word Ids: %s' % ([[letter for letter in to_seq(word.lower())] for word in words]))\n",
        "    inputWords = [\" \".join([reverse_dictionary[i] for i in to_seq(word)]) for word in words]\n",
        "    print('Input words: %s' % inputWords)\n",
        "    \n",
        "    print()\n",
        "    print(\"Output:\")\n",
        "    outputs = list()\n",
        "    for word in input_sentence.split(' '):\n",
        "        word_seq = to_seq(word.lower())\n",
        "        answer_logits = sess.run(logits, {input_data: [word_seq] * batch_size, label_sequence_length: [len(word_seq)] * batch_size, input_sequence_length: [len(word_seq)]*batch_size})[0]\n",
        "\n",
        "        \n",
        "        output_word = ''.join([reverse_dictionary[i] for i in answer_logits if i != pad])\n",
        "\n",
        "        print('Word Ids: %s' % ([i for i in answer_logits if i != pad]))\n",
        "        print('Response Word: %s' % (output_word))\n",
        "        outputs.append(output_word)\n",
        "    \n",
        "    print()\n",
        "    print(\"Sentence output: %s\" % (' '.join(outputs)))"
      ],
      "execution_count": 81,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:tensorflow:Restoring parameters from /content/gdrive/My Drive/IR/icdar2019/seq2seq/seq2seq.ckpt\n",
            "\n",
            "Original Text: грешка\n",
            "Word Ids: [[53, 94, 28, 23, 54, 82, 110, 110, 110, 110]]\n",
            "Input words: ['г р е ш к а <PAD> <PAD> <PAD> <PAD>']\n",
            "\n",
            "Output:\n",
            "Word Ids: [53, 94, 103, 23, 54, 82]\n",
            "Response Word: грѣшка\n",
            "\n",
            "Sentence output: грѣшка\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oS17oQ_f-KBJ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c5e80935-970a-4867-aa47-18ca2ca145ac"
      },
      "source": [
        "!zip -r model.zip ./saved"
      ],
      "execution_count": 82,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\tzip warning: name not matched: ./saved\n",
            "\n",
            "zip error: Nothing to do! (try: zip -r model.zip . -i ./saved)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "J1wQOW1NKOhn",
        "outputId": "cb67a9b9-e298-451e-bc48-3b2b07043663"
      },
      "source": [
        "test_dataset = path_to_dataset + '/correct_sentence.txt'\n",
        "test_dataset_words = path_to_dataset + '/correct_test_single.txt'\n",
        "test_pairs_sentences = create_pairs(test_dataset,start=1)\n",
        "test_pairs_single = create_pairs(test_dataset_words)"
      ],
      "execution_count": 83,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Reading lines...\n",
            "Reading lines...\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kEpVkptQKZKm",
        "outputId": "f8d444c1-d3d1-4bf8-cec1-eddc4bf8965b"
      },
      "source": [
        "hackset = set()\n",
        "for pair in test_pairs_single:\n",
        "  hackset.add(pair[0])\n",
        "\n",
        "print(random.sample(hackset, 10))"
      ],
      "execution_count": 84,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['живеете?', '-—', 'де', 'рхка,', 'п@б-трудолю-', 'заирещава', 'отзпвъ,', 'кадо', 'съдййствували', 'нощвитъ']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WiPv2G1hMII6",
        "outputId": "008a5295-3e13-430b-b8c4-4d182fdf285f"
      },
      "source": [
        "!pip install Levenshtein\n",
        "from Levenshtein import distance as levenshtein_distance"
      ],
      "execution_count": 85,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: Levenshtein in /usr/local/lib/python3.7/dist-packages (0.15.0)\n",
            "Requirement already satisfied: rapidfuzz<1.7,>=1.5.1 in /usr/local/lib/python3.7/dist-packages (from Levenshtein) (1.6.2)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from rapidfuzz<1.7,>=1.5.1->Levenshtein) (1.19.5)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gueMFjOYRR5U"
      },
      "source": [
        "def clean_up(word):\n",
        "  word = re.sub(r'\\n', '', word)\n",
        "  word = word.replace('@', '')\n",
        "  word = word.lower()\n",
        "  return word.strip()"
      ],
      "execution_count": 86,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3eO9m7dMRH_s",
        "outputId": "edaa3e7e-c62d-4bde-f4c5-a4963928cdd0"
      },
      "source": [
        "file_clada = path_to_dataset + '/clada.txt'\n",
        "def parse_clada(file):\n",
        "  clada_set = set()\n",
        "  with open(file, \"r\", encoding=\"utf-16\") as f:\n",
        "    raw_text = f.readlines()\n",
        "\n",
        "  for word in raw_text:\n",
        "    temp = clean_up(word)\n",
        "    if temp not in clada_set:\n",
        "      clada_set.add(temp)\n",
        "\n",
        "  return clada_set\n",
        "\n",
        "clada_set = parse_clada(file_clada)\n",
        "print(random.sample(clada_set, 10))\n",
        "print(len(clada_set))"
      ],
      "execution_count": 87,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['поизтягалото', 'разочароващиятъ', 'отлежаващи', 'поотстѫпете', 'тримирѣше', 'податнитѣ', 'семантично', 'метиловиятъ', 'имунизирана', 'разминиращо']\n",
            "1106371\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yvZeKtX_6rJ7",
        "outputId": "58ac8fbc-66c3-4d26-8e08-e4501de58624"
      },
      "source": [
        "pad = dictionary[\"<PAD>\"]\n",
        "\n",
        "checkpoint = path_to_dataset + '/seq2seq/seq2seq.ckpt'\n",
        "\n",
        "distances0 = []\n",
        "distances1 = []\n",
        "\n",
        "loaded_graph = tf.Graph()\n",
        "with tf.Session(graph=loaded_graph) as sess:\n",
        "    \n",
        "    # load the model\n",
        "    loader = tf.train.import_meta_graph(checkpoint + '.meta')\n",
        "    loader.restore(sess, checkpoint)\n",
        "\n",
        "    input_data = loaded_graph.get_tensor_by_name('inputs:0')\n",
        "    logits = loaded_graph.get_tensor_by_name('predictions:0')\n",
        "    input_sequence_length = loaded_graph.get_tensor_by_name('input_sequence_length:0')\n",
        "    label_sequence_length = loaded_graph.get_tensor_by_name('label_sequence_length:0')\n",
        "    \n",
        "    for pair in test_pairs_single:\n",
        "      input_sentence = clean_up(pair[0])\n",
        "      gs_sentence = clean_up(pair[1])\n",
        "\n",
        "      words = input_sentence.split(' ')\n",
        "      outputs = list()\n",
        "      for word in input_sentence.split(' '):\n",
        "          word_seq = to_seq(word)\n",
        "          answer_logits = sess.run(logits, {input_data: [word_seq] * batch_size, label_sequence_length: [len(word_seq)] * batch_size, input_sequence_length: [len(word_seq)] * batch_size})[0]          \n",
        "          output_word = ''.join([reverse_dictionary[i] for i in answer_logits if i != pad])\n",
        "\n",
        "          outputs.append(output_word if output_word in clada_set else word)\n",
        "\n",
        "      model_sentence_out = ' '.join(outputs)\n",
        "    \n",
        "\n",
        "\n",
        "      levdist0 = levenshtein_distance(input_sentence, gs_sentence) # distance between aligned and GS\n",
        "      levdist1 = levenshtein_distance(model_sentence_out, gs_sentence) # distance between model and GS\n",
        "\n",
        "      distances0.append(levdist0)\n",
        "      distances1.append(levdist1)"
      ],
      "execution_count": 88,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:tensorflow:Restoring parameters from /content/gdrive/My Drive/IR/icdar2019/seq2seq/seq2seq.ckpt\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AkGd_UKPeB6F",
        "outputId": "000a2c39-1d96-4e5c-9bb7-47bf2775e6ef"
      },
      "source": [
        "    print(sum(distances0))\n",
        "    print(sum(distances1))"
      ],
      "execution_count": 89,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "9325\n",
            "7585\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ves1QaWFVrKn",
        "outputId": "fd3cae8b-30ef-438a-a36c-076f4b77d286"
      },
      "source": [
        "improvement = (sum(distances0) - sum(distances1)) / sum(distances0)\n",
        "print(\"The improvement is {:.3f}%\".format(improvement * 100))"
      ],
      "execution_count": 90,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The improvement is 18.660%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ABxGASOqUvT3"
      },
      "source": [
        "def autocorrect(token):\n",
        "        candidates = self.candidates_edits1(token)\n",
        "\n",
        "        if len(candidates) > 0:\n",
        "            top_candidate = sorted(candidates, key=lambda candidate: self.probability(candidate, self.total))[:1]\n",
        "\n",
        "            return top_candidate[0]\n",
        "\n",
        "        return None"
      ],
      "execution_count": 91,
      "outputs": []
    }
  ]
}