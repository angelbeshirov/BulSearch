{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Error_correction.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.9"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "cellView": "both",
        "id": "MvEblsgEXxrd",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "36e57f1b-e301-4aae-ae16-f5fd55f7cd67"
      },
      "source": [
        "%tensorflow_version 1.x"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "TensorFlow 1.x selected.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9hih0Sx6_LZR"
      },
      "source": [
        "import os\n",
        "import numpy as np\n",
        "import random\n",
        "import re\n",
        "import string\n",
        "import tensorflow as tf\n",
        "import zipfile\n",
        "import pickle\n",
        "import matplotlib.pyplot as plt"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9K72xmdhE5X6",
        "outputId": "e950c155-aedb-4620-b5d7-41b3c8e09406"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')\n",
        "path_to_dataset = '/content/gdrive/My Drive/IR/icdar2019'"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/gdrive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "cellView": "both",
        "id": "Mvf09fjugFU_"
      },
      "source": [
        "def create_pairs(file, start=0):\n",
        "    \"\"\"\n",
        "    Create sentence pairs, where first sentence is the OCR-ed sentence and \n",
        "    2nd sentence is the GS sentence or the target one. This can be viewed as Machine Translation\n",
        "    task.\n",
        "    \"\"\"\n",
        "    print(\"Reading lines...\")\n",
        "\n",
        "    with open(file) as f:\n",
        "        data = f.readlines()\n",
        "\n",
        "    clean_sentences_ocr = []\n",
        "    clean_sentences_gs = []\n",
        "\n",
        "    for i in range(start, len(data), 2):\n",
        "      clean_sentences_ocr.append(clean_text(data[i]))\n",
        "      clean_sentences_gs.append(clean_text(data[i + 1]))\n",
        "\n",
        "    pairs = [[x, y] for x, y in zip(clean_sentences_ocr, clean_sentences_gs)]\n",
        "\n",
        "    return pairs"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TWmo6RbgFl2b"
      },
      "source": [
        "def clean_text(text):\n",
        "    text = re.sub(r'\\n', '', text)\n",
        "\n",
        "    return text.lower()"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tcAlSAyoGI1A",
        "outputId": "542b6bee-9369-48ab-f135-721d588b222d"
      },
      "source": [
        "def prepare_data(file):\n",
        "    return create_pairs(file)\n",
        "\n",
        "input_file = path_to_dataset + '/correct_single.txt'\n",
        "pairs = prepare_data(input_file)"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Reading lines...\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "q3DuIZsKFR_T",
        "outputId": "12589136-017f-474c-8347-2317c5b93583"
      },
      "source": [
        "print(\"Read {} word pairs\".format(len(pairs) // 2))\n",
        "pair1 = random.choice(pairs)\n",
        "pair2 = random.choice(pairs)\n",
        "pair3 = random.choice(pairs)\n",
        "\n",
        "print(\"Pair 1: OCR: {}, GS: {}, len1: {} and len2: {}\".format(pair1[0], pair1[1], len(pair1[0]), len(pair1[1])))\n",
        "print(\"Pair 2: OCR: {}, GS: {}, len1: {} and len2: {}\".format(pair2[0], pair2[1], len(pair2[0]), len(pair2[1])))\n",
        "print(\"Pair 3: OCR: {}, GS: {}, len1: {} and len2: {}\".format(pair3[0], pair3[1], len(pair3[0]), len(pair3[1])))"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Read 7122 word pairs\n",
            "Pair 1: OCR: някогашни, GS: нѣкогашпи, len1: 9 and len2: 9\n",
            "Pair 2: OCR: умътъ:, GS: умъ ъ:, len1: 6 and len2: 6\n",
            "Pair 3: OCR: нонравителп., GS: поправители., len1: 12 and len2: 12\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ga2CYACE-ghb"
      },
      "source": [
        "Create a small validation set."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "cellView": "both",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "w-oBpfFG-j43",
        "outputId": "7ed275bf-2ab0-4e1e-9c11-e272cf161058"
      },
      "source": [
        "valid_size = 1000\n",
        "valid_pairs = pairs[:valid_size]\n",
        "train_pairs = pairs[valid_size:]\n",
        "\n",
        "train_size = len(train_pairs)\n",
        "print(train_size, train_pairs[:5])\n",
        "print(valid_size, valid_pairs[:5])"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "13245 [['въренъ', 'вѣренъ'], ['бждн.', 'бѫди.'], ['унизи@', 'унизѝ'], ['с’', \"с'\"], ['измьна', 'измѣна']]\n",
            "1000 [['@@@350', '   350'], ['хриету', 'христу'], ['служители;', 'служитель;'], ['кръви', 'кръвь'], ['тьло', 'тѣло']]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HGC6SIFKIpXH",
        "outputId": "8829e86f-e689-4626-8b2f-c3cf50c5aa12"
      },
      "source": [
        "content = ''.join([p[0] + p[1] for p in pairs])\n",
        "\n",
        "invalid_chars = set(['^', '■', '•', '~', '§', '°', '®', '&', ' ', '½', 'λ', '„', '«'])\n",
        "all_chars = set(content) - invalid_chars\n",
        "\n",
        "all_chars = list(all_chars)\n",
        "print(all_chars)\n",
        "print(\"All chars are: {}\".format(len(all_chars)))"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[\"'\", '!', ']', '<', ',', '2', 'h', '.', 'л', 'р', '8', '|', '‐', '5', 'ѣ', 'м', 'у', '6', ')', 'l', '@', '‑', 'o', '0', '}', 'к', 'ц', 'm', 'ч', 'n', 'a', '[', '%', 'ῳ', '‘', '—', '’', 'б', '?', 'ю', 't', '3', 'в', 'и', 'ъ', 'я', 'г', 'п', 'γ', 'і', 'н', 'ῷ', 'z', 'j', '1', '―', 'b', 'ж', '̀', '“', ':', 'о', 'g', '\\\\', 'ӏ', '{', 'х', 'v', 'ӣ', '(', 'д', '\"', 'τ', 'f', 'd', 'й', '>', '9', 'u', '”', 'ό', 's', 'ѫ', 'p', ';', '*', '7', 'i', '/', '4', 'т', 'x', '́', 'щ', '-', 'а', 'ѭ', 'с', '#', 'e', 'k', 'ы', 'ь', 'ш', 'з', 'ф', '»', 'c', 'r', 'е']\n",
            "All chars are: 110\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "cellView": "both",
        "id": "KyVd8FxT5QBc"
      },
      "source": [
        "def logprob(predictions, labels):\n",
        "    \"\"\"Log-probability of the true labels in a predicted batch.\"\"\"\n",
        "    predictions[predictions < 1e-10] = 1e-10\n",
        "    return np.sum(np.multiply(labels, -np.log(predictions))) / labels.shape[0]\n",
        "\n",
        "def sample_distribution(distribution):\n",
        "    \"\"\"Sample one element from a distribution assumed to be an array of normalized probabilities.\n",
        "    \"\"\"\n",
        "    r = random.uniform(0, 1)\n",
        "    s = 0\n",
        "    for i in range(len(distribution)):\n",
        "        s += distribution[i]\n",
        "        if s >= r:\n",
        "            return i\n",
        "    \n",
        "    return len(distribution) - 1\n",
        "\n",
        "def sample(prediction):\n",
        "    \"\"\"Turn a prediction into a 1-hot encoded vecotr.\"\"\"\n",
        "    p = np.zeros(shape=[1, vocabulary_size], dtype=np.float)\n",
        "    p[0, sample_distribution(prediction[0])] = 1.0\n",
        "\n",
        "    return p\n",
        "\n",
        "def random_distribution():\n",
        "    \"\"\"Generate a random column of probabilities.\"\"\"\n",
        "    b = np.random.uniform(0.0, 1.0, size=[1, vocabulary_size])\n",
        "    return b / np.sum(b, 1)[:, None]"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "s1ihlV2t-KBI"
      },
      "source": [
        "from tensorflow.python.layers.core import Dense\n",
        "\n",
        "batch_size = 128\n",
        "rnn_size = 64\n",
        "num_layers = 2\n",
        "embedding_size = 64\n",
        "learning_rate = 0.001\n",
        "sequence_length = 10"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bcqZXTcf2JyJ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b646ed78-b9c5-490d-ed62-e59ce3ef54a9"
      },
      "source": [
        "print(\"Training pairs {}\".format(len(train_pairs) // 2))\n",
        "print(\"Validation pairs {}\".format(len(valid_pairs) // 2))"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training pairs 6622\n",
            "Validation pairs 500\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "E91WkI-K-KBI",
        "outputId": "81205678-9ce6-4503-e100-2223cd9a1486"
      },
      "source": [
        "def create_dictionaries():\n",
        "    special_words = ['<PAD>', '<UNK>', '<GO>',  '<END>']\n",
        "\n",
        "    words = all_chars + special_words\n",
        "    dictionary = {word: i for i, word in enumerate(words)}\n",
        "\n",
        "    return dictionary, dict(zip(dictionary.values(), dictionary.keys())) \n",
        "\n",
        "dictionary, reverse_dictionary = create_dictionaries()\n",
        "\n",
        "print(dictionary)\n",
        "print(reverse_dictionary)\n",
        "\n",
        "x_sentences = [pair[0] for pair in train_pairs]\n",
        "y_sentences = [pair[1] for pair in train_pairs]\n",
        "\n",
        "# Convert each word to dictionary representations\n",
        "x_ids = [[dictionary.get(letter, dictionary['<UNK>']) for letter in sentence] for sentence in x_sentences]\n",
        "y_ids = [[dictionary.get(letter, dictionary['<UNK>']) for letter in sentence] for sentence in y_sentences]\n",
        "\n",
        "print(\"Example raw data:\")\n",
        "print(train_pairs[:5])\n",
        "print(\"Example sequence\")\n",
        "print(x_ids[:5])\n",
        "print(\"\\n\")\n",
        "print(\"Example output\")\n",
        "print(y_ids[:5])"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{\"'\": 0, '!': 1, ']': 2, '<': 3, ',': 4, '2': 5, 'h': 6, '.': 7, 'л': 8, 'р': 9, '8': 10, '|': 11, '‐': 12, '5': 13, 'ѣ': 14, 'м': 15, 'у': 16, '6': 17, ')': 18, 'l': 19, '@': 20, '‑': 21, 'o': 22, '0': 23, '}': 24, 'к': 25, 'ц': 26, 'm': 27, 'ч': 28, 'n': 29, 'a': 30, '[': 31, '%': 32, 'ῳ': 33, '‘': 34, '—': 35, '’': 36, 'б': 37, '?': 38, 'ю': 39, 't': 40, '3': 41, 'в': 42, 'и': 43, 'ъ': 44, 'я': 45, 'г': 46, 'п': 47, 'γ': 48, 'і': 49, 'н': 50, 'ῷ': 51, 'z': 52, 'j': 53, '1': 54, '―': 55, 'b': 56, 'ж': 57, '̀': 58, '“': 59, ':': 60, 'о': 61, 'g': 62, '\\\\': 63, 'ӏ': 64, '{': 65, 'х': 66, 'v': 67, 'ӣ': 68, '(': 69, 'д': 70, '\"': 71, 'τ': 72, 'f': 73, 'd': 74, 'й': 75, '>': 76, '9': 77, 'u': 78, '”': 79, 'ό': 80, 's': 81, 'ѫ': 82, 'p': 83, ';': 84, '*': 85, '7': 86, 'i': 87, '/': 88, '4': 89, 'т': 90, 'x': 91, '́': 92, 'щ': 93, '-': 94, 'а': 95, 'ѭ': 96, 'с': 97, '#': 98, 'e': 99, 'k': 100, 'ы': 101, 'ь': 102, 'ш': 103, 'з': 104, 'ф': 105, '»': 106, 'c': 107, 'r': 108, 'е': 109, '<PAD>': 110, '<UNK>': 111, '<GO>': 112, '<END>': 113}\n",
            "{0: \"'\", 1: '!', 2: ']', 3: '<', 4: ',', 5: '2', 6: 'h', 7: '.', 8: 'л', 9: 'р', 10: '8', 11: '|', 12: '‐', 13: '5', 14: 'ѣ', 15: 'м', 16: 'у', 17: '6', 18: ')', 19: 'l', 20: '@', 21: '‑', 22: 'o', 23: '0', 24: '}', 25: 'к', 26: 'ц', 27: 'm', 28: 'ч', 29: 'n', 30: 'a', 31: '[', 32: '%', 33: 'ῳ', 34: '‘', 35: '—', 36: '’', 37: 'б', 38: '?', 39: 'ю', 40: 't', 41: '3', 42: 'в', 43: 'и', 44: 'ъ', 45: 'я', 46: 'г', 47: 'п', 48: 'γ', 49: 'і', 50: 'н', 51: 'ῷ', 52: 'z', 53: 'j', 54: '1', 55: '―', 56: 'b', 57: 'ж', 58: '̀', 59: '“', 60: ':', 61: 'о', 62: 'g', 63: '\\\\', 64: 'ӏ', 65: '{', 66: 'х', 67: 'v', 68: 'ӣ', 69: '(', 70: 'д', 71: '\"', 72: 'τ', 73: 'f', 74: 'd', 75: 'й', 76: '>', 77: '9', 78: 'u', 79: '”', 80: 'ό', 81: 's', 82: 'ѫ', 83: 'p', 84: ';', 85: '*', 86: '7', 87: 'i', 88: '/', 89: '4', 90: 'т', 91: 'x', 92: '́', 93: 'щ', 94: '-', 95: 'а', 96: 'ѭ', 97: 'с', 98: '#', 99: 'e', 100: 'k', 101: 'ы', 102: 'ь', 103: 'ш', 104: 'з', 105: 'ф', 106: '»', 107: 'c', 108: 'r', 109: 'е', 110: '<PAD>', 111: '<UNK>', 112: '<GO>', 113: '<END>'}\n",
            "Example raw data:\n",
            "[['въренъ', 'вѣренъ'], ['бждн.', 'бѫди.'], ['унизи@', 'унизѝ'], ['с’', \"с'\"], ['измьна', 'измѣна']]\n",
            "Example sequence\n",
            "[[42, 44, 9, 109, 50, 44], [37, 57, 70, 50, 7], [16, 50, 43, 104, 43, 20], [97, 36], [43, 104, 15, 102, 50, 95]]\n",
            "\n",
            "\n",
            "Example output\n",
            "[[42, 14, 9, 109, 50, 44], [37, 82, 70, 43, 7], [16, 50, 43, 104, 43, 58], [97, 0], [43, 104, 15, 14, 50, 95]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nIO2ibct-KBI"
      },
      "source": [
        "def create_cell(rnn_size):\n",
        "    cell = tf.contrib.rnn.LSTMCell(rnn_size,initializer=tf.random_uniform_initializer(-0.1, 0.1, seed=2))\n",
        "    \n",
        "    return cell"
      ],
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7hx4w-tU-KBI"
      },
      "source": [
        "def get_model_inputs():\n",
        "    inputs = tf.placeholder(tf.int32, [batch_size, None], name = 'inputs')\n",
        "    labels = tf.placeholder(tf.int32, [batch_size, None])\n",
        "    lr = tf.placeholder(tf.float32)\n",
        "\n",
        "    input_sequence_length = tf.placeholder(tf.int32, (batch_size,), name = 'input_sequence_length')\n",
        "    label_sequence_length = tf.placeholder(tf.int32, (batch_size,), name = 'label_sequence_length')\n",
        "    \n",
        "    max_label_sequence_length = tf.reduce_max(label_sequence_length)\n",
        "    \n",
        "    return inputs, labels, lr, input_sequence_length, label_sequence_length, max_label_sequence_length"
      ],
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3SnYtrJ1-KBI"
      },
      "source": [
        "def encoding_layer(inputs, rnn_size, num_layers, input_sequence_length, vocab_size, embedding_size):\n",
        "\n",
        "    embedded_input = tf.contrib.layers.embed_sequence(inputs, vocab_size, embedding_size)\n",
        "    encoder_cell = tf.contrib.rnn.MultiRNNCell([create_cell(rnn_size) for _ in range(num_layers)])\n",
        "    encoder_output, encoder_state = tf.nn.dynamic_rnn(encoder_cell, embedded_input, sequence_length=input_sequence_length, dtype=tf.float32)\n",
        "    \n",
        "    return encoder_output, encoder_state"
      ],
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fSCshWvK-KBI"
      },
      "source": [
        "# Some basic preprocessing to remove the last char and add the GO symbol for the decoder\n",
        "def process_decoder_input(labels, dictionary, batch_size):\n",
        "    ending = tf.strided_slice(labels, [0, 0], [batch_size, -1], [1, 1])\n",
        "    decoder_input = tf.concat([tf.fill([batch_size, 1], dictionary['<GO>']), ending], 1)\n",
        "\n",
        "    return decoder_input"
      ],
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SSHtZ0bK-KBI"
      },
      "source": [
        "def decoding_layer(dictionary, embedding_size, num_layers, rnn_size, labels_sequence_length, max_label_sequence_length, encoder_state, decoder_input):\n",
        "\n",
        "    vocab_size = len(dictionary)\n",
        "    decoder_embeddings = tf.Variable(tf.random_uniform([vocab_size, embedding_size]))\n",
        "    decoder_embed_input = tf.nn.embedding_lookup(decoder_embeddings, decoder_input)\n",
        "\n",
        "    decoder_cell = tf.contrib.rnn.MultiRNNCell([create_cell(rnn_size) for _ in range(num_layers)])\n",
        "     \n",
        "    output_layer = Dense(vocab_size, kernel_initializer=tf.truncated_normal_initializer(mean = 0.0, stddev=0.1))\n",
        "\n",
        "    with tf.variable_scope(\"decode\"):\n",
        "        training_helper = tf.contrib.seq2seq.TrainingHelper(inputs=decoder_embed_input, sequence_length=labels_sequence_length, time_major=False)\n",
        "        training_decoder = tf.contrib.seq2seq.BasicDecoder(decoder_cell, training_helper, encoder_state, output_layer) \n",
        "        training_decoder_output = tf.contrib.seq2seq.dynamic_decode(training_decoder,impute_finished=True, maximum_iterations=max_label_sequence_length)[0]\n",
        "\n",
        "    with tf.variable_scope(\"decode\", reuse=True):\n",
        "        start_tokens = tf.tile(tf.constant([dictionary['<GO>']], dtype=tf.int32), [batch_size], name='start_tokens')\n",
        "\n",
        "        inference_helper = tf.contrib.seq2seq.GreedyEmbeddingHelper(decoder_embeddings, start_tokens, dictionary['<END>'])\n",
        "        inference_decoder = tf.contrib.seq2seq.BasicDecoder(decoder_cell,inference_helper,encoder_state,output_layer)\n",
        "        inference_decoder_output = tf.contrib.seq2seq.dynamic_decode(inference_decoder, impute_finished=True, maximum_iterations=max_label_sequence_length)[0]\n",
        "    \n",
        "    return training_decoder_output, inference_decoder_output"
      ],
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qoqx-OjN-KBI"
      },
      "source": [
        "def seq2seq_model(input_data, labels, lr, inputs_sequence_length, labels_sequence_length, max_label_sequence_length, vocab_size, embedding_size, rnn_size, num_layers):\n",
        "    \n",
        "    _, encoder_state = encoding_layer(input_data, rnn_size, num_layers, inputs_sequence_length, vocab_size, embedding_size)\n",
        "    \n",
        "    decoder_input = process_decoder_input(labels, dictionary, batch_size)\n",
        "    \n",
        "    training_decoder_output, inference_decoder_output = decoding_layer(dictionary, embedding_size, num_layers, rnn_size, labels_sequence_length,\\\n",
        "                                                                       max_label_sequence_length, encoder_state, decoder_input) \n",
        "    \n",
        "    return training_decoder_output, inference_decoder_output"
      ],
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RnlkqYjv-KBJ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5d26e51a-a64c-4c96-ff6c-2ba09f1bd01c"
      },
      "source": [
        "train_graph = tf.Graph()\n",
        "\n",
        "with train_graph.as_default():\n",
        "    \n",
        "    input_data, labels, lr, input_sequence_length, label_sequence_length, max_label_sequence_length = get_model_inputs()\n",
        "    \n",
        "    training_decoder_output, inference_decoder_output = seq2seq_model(input_data, labels, lr, input_sequence_length,label_sequence_length, max_label_sequence_length,\\\n",
        "                                                                      len(dictionary),embedding_size, rnn_size, num_layers)    \n",
        "\n",
        "    training_logits = tf.identity(training_decoder_output.rnn_output, 'logits')\n",
        "    inference_logits = tf.identity(inference_decoder_output.sample_id, name='predictions')\n",
        "    \n",
        "    masks = tf.sequence_mask(label_sequence_length, max_label_sequence_length, dtype=tf.float32, name='masks')\n",
        "\n",
        "    with tf.name_scope(\"optimization\"):\n",
        "\n",
        "        cost = tf.contrib.seq2seq.sequence_loss(training_logits, labels, masks)\n",
        "\n",
        "        optimizer = tf.train.AdamOptimizer(lr)\n",
        "\n",
        "        gradients = optimizer.compute_gradients(cost)\n",
        "        capped_gradients = [(tf.clip_by_value(grad, -5., 5.), var) for grad, var in gradients if grad is not None]\n",
        "        train_op = optimizer.apply_gradients(capped_gradients)"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "WARNING:tensorflow:\n",
            "The TensorFlow contrib module will not be included in TensorFlow 2.0.\n",
            "For more information, please see:\n",
            "  * https://github.com/tensorflow/community/blob/master/rfcs/20180907-contrib-sunset.md\n",
            "  * https://github.com/tensorflow/addons\n",
            "  * https://github.com/tensorflow/io (for I/O related ops)\n",
            "If you depend on functionality not listed there, please file an issue.\n",
            "\n",
            "WARNING:tensorflow:From <ipython-input-14-ab690fd1a1d1>:2: LSTMCell.__init__ (from tensorflow.python.ops.rnn_cell_impl) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "This class is equivalent as tf.keras.layers.LSTMCell, and will be replaced by that in Tensorflow 2.0.\n",
            "WARNING:tensorflow:From <ipython-input-16-ef63aeabc3ea>:4: MultiRNNCell.__init__ (from tensorflow.python.ops.rnn_cell_impl) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "This class is equivalent as tf.keras.layers.StackedRNNCells, and will be replaced by that in Tensorflow 2.0.\n",
            "WARNING:tensorflow:From <ipython-input-16-ef63aeabc3ea>:5: dynamic_rnn (from tensorflow.python.ops.rnn) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please use `keras.layers.RNN(cell)`, which is equivalent to this API\n",
            "WARNING:tensorflow:From /tensorflow-1.15.2/python3.7/tensorflow_core/python/ops/rnn_cell_impl.py:958: Layer.add_variable (from tensorflow.python.keras.engine.base_layer) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please use `layer.add_weight` method instead.\n",
            "WARNING:tensorflow:From /tensorflow-1.15.2/python3.7/tensorflow_core/python/ops/rnn_cell_impl.py:962: calling Zeros.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Call initializer instance with the dtype argument instead of passing it to the constructor\n",
            "WARNING:tensorflow:From /tensorflow-1.15.2/python3.7/tensorflow_core/python/ops/rnn.py:244: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use tf.where in 2.0, which has the same broadcast rule as np.where\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UhbYaaAi-KBJ"
      },
      "source": [
        "def pad_batch(batch, pad_int):\n",
        "    # make sure each word has the same length\n",
        "    max_length = max([len(word) for word in batch])\n",
        "    return [word + [pad_int] * (max_length - len(word)) for word in batch]"
      ],
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FH1QCFtu-KBJ"
      },
      "source": [
        "class BatchGenerator(object):\n",
        "    def __init__(self, labels, inputs, batch_size, input_pad_int, label_pad_int):\n",
        "        self._labels = labels\n",
        "        self._inputs = inputs\n",
        "        self._batch_size = batch_size\n",
        "        self._input_pad_int = input_pad_int\n",
        "        self._label_pad_int = label_pad_int\n",
        "        self._cursor = 0\n",
        "  \n",
        "    def next(self):\n",
        "        # Generates a single batch\n",
        "        start_i = self._cursor * self._batch_size\n",
        "        input_batch = self._inputs[start_i:start_i + self._batch_size]\n",
        "        label_batch = self._labels[start_i:start_i + self._batch_size]\n",
        "        pad_input_batch = np.array(pad_batch(input_batch, self._input_pad_int))\n",
        "        pad_label_batch = np.array(pad_batch(label_batch, self._label_pad_int))\n",
        "        \n",
        "        pad_label_lengths = []\n",
        "        for i in pad_label_batch:\n",
        "            pad_label_lengths.append(len(i))\n",
        "\n",
        "        pad_input_lengths = []\n",
        "        for i in pad_input_batch:\n",
        "            pad_input_lengths.append(len(i))\n",
        "            \n",
        "        self._cursor = self._cursor + 1\n",
        "        \n",
        "        return pad_label_batch, pad_input_batch, pad_label_lengths, pad_input_lengths"
      ],
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Vn60g7lL-KBJ",
        "outputId": "d6c0d293-f76f-40f5-d113-6802e0a7f7ff"
      },
      "source": [
        "train_input = x_ids[batch_size:]\n",
        "train_labels = y_ids[batch_size:]\n",
        "\n",
        "valid_input = x_ids[:batch_size]\n",
        "valid_labels = y_ids[:batch_size]\n",
        "\n",
        "batch_generator_valid = BatchGenerator(valid_labels, valid_input, batch_size, dictionary['<PAD>'], dictionary['<PAD>'])\n",
        "batch_generator_train = BatchGenerator(train_labels, train_input, batch_size, dictionary['<PAD>'], dictionary['<PAD>'])\n",
        "\n",
        "\n",
        "(valid_labels_batch, valid_input_batch, valid_labels_lengths, valid_input_lengths) = batch_generator_valid.next()\n",
        "\n",
        "checkpoint = \"seq2seq.ckpt\"\n",
        "training_epochs = 100\n",
        "\n",
        "loss_train = []\n",
        "loss_valid = []\n",
        "\n",
        "data = []\n",
        "for batch_i in range(0, len(train_input) // batch_size):\n",
        "    data.append(batch_generator_train.next())\n",
        "\n",
        "\n",
        "with tf.Session(graph=train_graph) as sess:\n",
        "    sess.run(tf.global_variables_initializer())\n",
        "\n",
        "    for epoch in range(training_epochs):\n",
        "\n",
        "      for labels_batch, input_batch, labels_lengths, input_lengths in data:\n",
        "        _, loss = sess.run([train_op, cost],\n",
        "        {\n",
        "            input_data: input_batch,\n",
        "            labels: labels_batch,\n",
        "            lr: learning_rate,\n",
        "            label_sequence_length: labels_lengths,\n",
        "            input_sequence_length: input_lengths\n",
        "          })\n",
        "        \n",
        "      validation_loss = sess.run(\n",
        "      [cost],\n",
        "      {\n",
        "          input_data: valid_input_batch,\n",
        "          labels: valid_labels_batch,\n",
        "          lr: learning_rate,\n",
        "          label_sequence_length: valid_labels_lengths,\n",
        "          input_sequence_length: valid_input_lengths\n",
        "       })\n",
        "      \n",
        "      print('Epoch %d/%d - Loss: %.3f  - Validation loss: %.3f' % (epoch, training_epochs, loss, validation_loss[0]))\n",
        "      loss_train.append(loss)\n",
        "      loss_valid.append(validation_loss[0])\n",
        "\n",
        "    # save the model state\n",
        "    saver = tf.train.Saver()\n",
        "    saver.save(sess, checkpoint)\n",
        "    print('Model Trained and Saved')"
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 0/100 - Loss: 1.621  - Validation loss: 1.398\n",
            "Epoch 1/100 - Loss: 1.378  - Validation loss: 1.200\n",
            "Epoch 2/100 - Loss: 1.308  - Validation loss: 1.149\n",
            "Epoch 3/100 - Loss: 1.279  - Validation loss: 1.139\n",
            "Epoch 4/100 - Loss: 1.259  - Validation loss: 1.111\n",
            "Epoch 5/100 - Loss: 1.254  - Validation loss: 1.101\n",
            "Epoch 6/100 - Loss: 1.229  - Validation loss: 1.093\n",
            "Epoch 7/100 - Loss: 1.220  - Validation loss: 1.083\n",
            "Epoch 8/100 - Loss: 1.198  - Validation loss: 1.074\n",
            "Epoch 9/100 - Loss: 1.153  - Validation loss: 1.043\n",
            "Epoch 10/100 - Loss: 1.074  - Validation loss: 1.002\n",
            "Epoch 11/100 - Loss: 1.028  - Validation loss: 0.972\n",
            "Epoch 12/100 - Loss: 0.998  - Validation loss: 0.957\n",
            "Epoch 13/100 - Loss: 0.971  - Validation loss: 0.945\n",
            "Epoch 14/100 - Loss: 0.941  - Validation loss: 0.918\n",
            "Epoch 15/100 - Loss: 0.912  - Validation loss: 0.896\n",
            "Epoch 16/100 - Loss: 0.891  - Validation loss: 0.882\n",
            "Epoch 17/100 - Loss: 0.856  - Validation loss: 0.852\n",
            "Epoch 18/100 - Loss: 0.831  - Validation loss: 0.831\n",
            "Epoch 19/100 - Loss: 0.807  - Validation loss: 0.812\n",
            "Epoch 20/100 - Loss: 0.773  - Validation loss: 0.792\n",
            "Epoch 21/100 - Loss: 0.741  - Validation loss: 0.770\n",
            "Epoch 22/100 - Loss: 0.721  - Validation loss: 0.750\n",
            "Epoch 23/100 - Loss: 0.689  - Validation loss: 0.732\n",
            "Epoch 24/100 - Loss: 0.664  - Validation loss: 0.713\n",
            "Epoch 25/100 - Loss: 0.632  - Validation loss: 0.686\n",
            "Epoch 26/100 - Loss: 0.610  - Validation loss: 0.672\n",
            "Epoch 27/100 - Loss: 0.597  - Validation loss: 0.649\n",
            "Epoch 28/100 - Loss: 0.559  - Validation loss: 0.636\n",
            "Epoch 29/100 - Loss: 0.533  - Validation loss: 0.615\n",
            "Epoch 30/100 - Loss: 0.518  - Validation loss: 0.605\n",
            "Epoch 31/100 - Loss: 0.490  - Validation loss: 0.578\n",
            "Epoch 32/100 - Loss: 0.474  - Validation loss: 0.559\n",
            "Epoch 33/100 - Loss: 0.464  - Validation loss: 0.546\n",
            "Epoch 34/100 - Loss: 0.466  - Validation loss: 0.535\n",
            "Epoch 35/100 - Loss: 0.438  - Validation loss: 0.517\n",
            "Epoch 36/100 - Loss: 0.422  - Validation loss: 0.506\n",
            "Epoch 37/100 - Loss: 0.416  - Validation loss: 0.497\n",
            "Epoch 38/100 - Loss: 0.398  - Validation loss: 0.491\n",
            "Epoch 39/100 - Loss: 0.380  - Validation loss: 0.478\n",
            "Epoch 40/100 - Loss: 0.366  - Validation loss: 0.467\n",
            "Epoch 41/100 - Loss: 0.356  - Validation loss: 0.461\n",
            "Epoch 42/100 - Loss: 0.344  - Validation loss: 0.454\n",
            "Epoch 43/100 - Loss: 0.330  - Validation loss: 0.448\n",
            "Epoch 44/100 - Loss: 0.317  - Validation loss: 0.437\n",
            "Epoch 45/100 - Loss: 0.305  - Validation loss: 0.429\n",
            "Epoch 46/100 - Loss: 0.294  - Validation loss: 0.422\n",
            "Epoch 47/100 - Loss: 0.286  - Validation loss: 0.418\n",
            "Epoch 48/100 - Loss: 0.277  - Validation loss: 0.409\n",
            "Epoch 49/100 - Loss: 0.267  - Validation loss: 0.401\n",
            "Epoch 50/100 - Loss: 0.259  - Validation loss: 0.397\n",
            "Epoch 51/100 - Loss: 0.249  - Validation loss: 0.390\n",
            "Epoch 52/100 - Loss: 0.243  - Validation loss: 0.384\n",
            "Epoch 53/100 - Loss: 0.236  - Validation loss: 0.381\n",
            "Epoch 54/100 - Loss: 0.228  - Validation loss: 0.373\n",
            "Epoch 55/100 - Loss: 0.221  - Validation loss: 0.367\n",
            "Epoch 56/100 - Loss: 0.217  - Validation loss: 0.362\n",
            "Epoch 57/100 - Loss: 0.210  - Validation loss: 0.358\n",
            "Epoch 58/100 - Loss: 0.206  - Validation loss: 0.354\n",
            "Epoch 59/100 - Loss: 0.205  - Validation loss: 0.351\n",
            "Epoch 60/100 - Loss: 0.200  - Validation loss: 0.349\n",
            "Epoch 61/100 - Loss: 0.197  - Validation loss: 0.346\n",
            "Epoch 62/100 - Loss: 0.198  - Validation loss: 0.342\n",
            "Epoch 63/100 - Loss: 0.195  - Validation loss: 0.344\n",
            "Epoch 64/100 - Loss: 0.192  - Validation loss: 0.339\n",
            "Epoch 65/100 - Loss: 0.194  - Validation loss: 0.334\n",
            "Epoch 66/100 - Loss: 0.183  - Validation loss: 0.332\n",
            "Epoch 67/100 - Loss: 0.178  - Validation loss: 0.324\n",
            "Epoch 68/100 - Loss: 0.177  - Validation loss: 0.320\n",
            "Epoch 69/100 - Loss: 0.175  - Validation loss: 0.317\n",
            "Epoch 70/100 - Loss: 0.178  - Validation loss: 0.318\n",
            "Epoch 71/100 - Loss: 0.167  - Validation loss: 0.317\n",
            "Epoch 72/100 - Loss: 0.161  - Validation loss: 0.312\n",
            "Epoch 73/100 - Loss: 0.160  - Validation loss: 0.310\n",
            "Epoch 74/100 - Loss: 0.157  - Validation loss: 0.308\n",
            "Epoch 75/100 - Loss: 0.154  - Validation loss: 0.309\n",
            "Epoch 76/100 - Loss: 0.151  - Validation loss: 0.308\n",
            "Epoch 77/100 - Loss: 0.147  - Validation loss: 0.306\n",
            "Epoch 78/100 - Loss: 0.143  - Validation loss: 0.308\n",
            "Epoch 79/100 - Loss: 0.139  - Validation loss: 0.307\n",
            "Epoch 80/100 - Loss: 0.137  - Validation loss: 0.309\n",
            "Epoch 81/100 - Loss: 0.136  - Validation loss: 0.310\n",
            "Epoch 82/100 - Loss: 0.131  - Validation loss: 0.309\n",
            "Epoch 83/100 - Loss: 0.128  - Validation loss: 0.315\n",
            "Epoch 84/100 - Loss: 0.126  - Validation loss: 0.317\n",
            "Epoch 85/100 - Loss: 0.124  - Validation loss: 0.317\n",
            "Epoch 86/100 - Loss: 0.125  - Validation loss: 0.316\n",
            "Epoch 87/100 - Loss: 0.131  - Validation loss: 0.315\n",
            "Epoch 88/100 - Loss: 0.133  - Validation loss: 0.312\n",
            "Epoch 89/100 - Loss: 0.134  - Validation loss: 0.314\n",
            "Epoch 90/100 - Loss: 0.136  - Validation loss: 0.321\n",
            "Epoch 91/100 - Loss: 0.136  - Validation loss: 0.322\n",
            "Epoch 92/100 - Loss: 0.134  - Validation loss: 0.325\n",
            "Epoch 93/100 - Loss: 0.130  - Validation loss: 0.325\n",
            "Epoch 94/100 - Loss: 0.126  - Validation loss: 0.322\n",
            "Epoch 95/100 - Loss: 0.122  - Validation loss: 0.318\n",
            "Epoch 96/100 - Loss: 0.120  - Validation loss: 0.319\n",
            "Epoch 97/100 - Loss: 0.119  - Validation loss: 0.317\n",
            "Epoch 98/100 - Loss: 0.120  - Validation loss: 0.317\n",
            "Epoch 99/100 - Loss: 0.123  - Validation loss: 0.313\n",
            "Model Trained and Saved\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zoSEasTUcvWt"
      },
      "source": [
        "saved_model_path = path_to_dataset + '/seq2seq/'"
      ],
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 296
        },
        "id": "ysbpdwiPoDZ9",
        "outputId": "d8eab320-f836-41b5-a372-71a463a43d63"
      },
      "source": [
        "plt.plot(loss_train, label='training loss')\n",
        "plt.plot(loss_valid, label='validation loss')\n",
        "plt.xlabel(\"Epoch\")\n",
        "plt.ylabel(\"Loss\")\n",
        "plt.legend()"
      ],
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.legend.Legend at 0x7fcb00416b10>"
            ]
          },
          "metadata": {},
          "execution_count": 25
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYIAAAEGCAYAAABo25JHAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjIsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+WH4yJAAAgAElEQVR4nO3deXxU1dnA8d8zk0kme0JIICSBsEPYISyKCIhaQAUXFBFULEq1Vdu3LXVp69K+vtX3tVRR1KK4r4iiWFBEFsGKsglh3wOELQmQfc+c9487pAGSECCTSTLP9/OZDzP3nnvvc3P5zDP3nHPPEWMMSimlfJfN2wEopZTyLk0ESinl4zQRKKWUj9NEoJRSPk4TgVJK+Tg/bwdwvpo3b24SExO9HYZSSjUq69atyzTGRFe1rtElgsTERNauXevtMJRSqlERkf3VrdOqIaWU8nGaCJRSysdpIlBKKR/X6NoIlFL1r7S0lLS0NIqKirwdijoHp9NJfHw8Doej1ttoIlBKnVNaWhqhoaEkJiYiIt4OR1XDGMPx48dJS0ujbdu2td5Oq4aUUudUVFREVFSUJoEGTkSIioo67zs3TQRKqVrRJNA4XMh18plEsONoLv+3aDtZBSXeDkUppRoUjyUCEXldRNJFZHMNZYaJyAYR2SIi33oqFoDU4/nMXLaHtJOFnjyMUsoDsrKyeOmlly5o29GjR5OVlVVjmccee4xvvvnmgvZ/psTERDIzM+tkX/XFk3cEbwIjq1spIhHAS8AYY0w34GYPxkJMaAAA6bna60GpxqamRFBWVlbjtgsXLiQiIqLGMn/5y1+48sorLzi+xs5jicAYswI4UUOR24BPjTEH3OXTPRULQLQ7EWTkFnvyMEopD3j44YfZs2cPvXv3Ztq0aSxfvpwhQ4YwZswYkpKSALj++uvp168f3bp1Y9asWRXbnvqFnpqaSteuXbnnnnvo1q0bV199NYWFVg3B5MmTmTt3bkX5xx9/nL59+9KjRw+2b98OQEZGBldddRXdunXj7rvvpk2bNuf85T99+nS6d+9O9+7dee655wDIz8/nmmuuoVevXnTv3p2PPvqo4hyTkpLo2bMnv//97+v2D3gO3uw+2glwiMhyIBR43hjzdlUFRWQqMBWgdevWF3SwU4kgPUcTgVIX48kvtrD1cE6d7jOpVRiPX9et2vVPP/00mzdvZsOGDQAsX76c9evXs3nz5opukq+//jrNmjWjsLCQ/v37c9NNNxEVFXXafnbt2sUHH3zAq6++yi233MInn3zCpEmTzjpe8+bNWb9+PS+99BLPPvssr732Gk8++SRXXHEFjzzyCF999RWzZ8+u8ZzWrVvHG2+8wY8//ogxhoEDBzJ06FD27t1Lq1atWLBgAQDZ2dkcP36cefPmsX37dkTknFVZdc2bjcV+QD/gGuBnwJ9FpFNVBY0xs4wxycaY5OjoKgfPO6cAPzsRQQ7S9Y5AqSZhwIABp/WVnzFjBr169WLQoEEcPHiQXbt2nbVN27Zt6d27NwD9+vUjNTW1yn3feOONZ5X57rvvuPXWWwEYOXIkkZGRNcb33XffccMNNxAcHExISAg33ngjK1eupEePHixevJiHHnqIlStXEh4eTnh4OE6nkylTpvDpp58SFBR0vn+Oi+LNO4I04LgxJh/IF5EVQC9gp6cOGB0SoFVDSl2kmn6516fg4OCK98uXL+ebb75h1apVBAUFMWzYsCr70gcEBFS8t9vtFVVD1ZWz2+3nbIM4X506dWL9+vUsXLiQP/3pT4wYMYLHHnuM1atXs2TJEubOncuLL77I0qVL6/S4NfHmHcHnwGUi4iciQcBAYJsnDxgTFqCNxUo1QqGhoeTm5la7Pjs7m8jISIKCgti+fTs//PBDnccwePBg5syZA8DXX3/NyZMnayw/ZMgQPvvsMwoKCsjPz2fevHkMGTKEw4cPExQUxKRJk5g2bRrr168nLy+P7OxsRo8ezT/+8Q82btxY5/HXxGN3BCLyATAMaC4iacDjgAPAGPOKMWabiHwFpAAu4DVjTLVdTetCdEgAa/fXfPGUUg1PVFQUgwcPpnv37owaNYprrrnmtPUjR47klVdeoWvXrnTu3JlBgwbVeQyPP/44EyZM4J133uGSSy6hZcuWhIaGVlu+b9++TJ48mQEDBgBw991306dPHxYtWsS0adOw2Ww4HA5efvllcnNzGTt2LEVFRRhjmD59ep3HXxMxxtTrAS9WcnKyudCJaf5n4Tbe+j6V7X8dqU9JKnUetm3bRteuXb0dhlcVFxdjt9vx8/Nj1apV3HfffRWN1w1NVddLRNYZY5KrKu9Tg87FhAZQXOYip6iM8MDaj8ynlFIHDhzglltuweVy4e/vz6uvvurtkOqMTyWCys8SaCJQSp2Pjh078tNPP3k7DI/wmbGGoNKzBNpgrJRSFXwqEcTo08VKKXUWn0oE0aFOQBOBUkpV5lOJIMzpR4CfTZ8uVkqpSnwqEYgI0aH6dLFSviAkJASAw4cPM27cuCrLDBs2jHN1R3/uuecoKCio+FybYa1r44knnuDZZ5+96P3UBZ9KBGC1E2hjsVK+o1WrVhUji16IMxNBbYa1bmx8LhFEhwboCKRKNTIPP/wwM2fOrPh86td0Xl4eI0aMqBgy+vPPPz9r29TUVLp37w5AYWEht956K127duWGG244bayh++67j+TkZLp168bjjz8OWAPZHT58mOHDhzN8+HDg9IlnqhpmuqbhrquzYcMGBg0aRM+ePbnhhhsqhq+YMWNGxdDUpwa8+/bbb+nduze9e/emT58+NQ69UVs+9RwBQEyokx/31TRNglKqRl8+DEc31e0+W/aAUU9Xu3r8+PH85je/4Ve/+hUAc+bMYdGiRTidTubNm0dYWBiZmZkMGjSIMWPGVDtywMsvv0xQUBDbtm0jJSWFvn37Vqx76qmnaNasGeXl5YwYMYKUlBQefPBBpk+fzrJly2jevPlp+6pumOnIyMhaD3d9yh133MELL7zA0KFDeeyxx3jyySd57rnnePrpp9m3bx8BAQEV1VHPPvssM2fOZPDgweTl5eF0Omv9Z66Oz90RxIQGkFVQSnFZubdDUUrVUp8+fUhPT+fw4cNs3LiRyMhIEhISMMbw6KOP0rNnT6688koOHTrEsWPHqt3PihUrKr6Qe/bsSc+ePSvWzZkzh759+9KnTx+2bNnC1q1ba4ypumGmofbDXYM1YF5WVhZDhw4F4M4772TFihUVMU6cOJF3330XPz/rd/vgwYP57W9/y4wZM8jKyqpYfjF87o7g1ENlmXklxEUEejkapRqhGn65e9LNN9/M3LlzOXr0KOPHjwfgvffeIyMjg3Xr1uFwOEhMTKxy+Olz2bdvH88++yxr1qwhMjKSyZMnX9B+TqntcNfnsmDBAlasWMEXX3zBU089xaZNm3j44Ye55pprWLhwIYMHD2bRokV06dLlgmMFX7wjCDs1U5k2GCvVmIwfP54PP/yQuXPncvPN1hTn2dnZxMTE4HA4WLZsGfv3769xH5dffjnvv/8+AJs3byYlJQWAnJwcgoODCQ8P59ixY3z55ZcV21Q3BHZ1w0yfr/DwcCIjIyvuJt555x2GDh2Ky+Xi4MGDDB8+nGeeeYbs7Gzy8vLYs2cPPXr04KGHHqJ///4VU2leDN+7Iwix6tP0WQKlGpdu3bqRm5tLXFwcsbGxAEycOJHrrruOHj16kJycfM5fxvfddx933XUXXbt2pWvXrvTr1w+AXr160adPH7p06UJCQgKDBw+u2Gbq1KmMHDmSVq1asWzZsorl1Q0zXVM1UHXeeust7r33XgoKCmjXrh1vvPEG5eXlTJo0iezsbIwxPPjgg0RERPDnP/+ZZcuWYbPZ6NatG6NGjTrv453Jp4ahBjiWU8TA/1nCf1/fnUmD2tRhZEo1XToMdeNyvsNQ+1zVUFSwPyJ6R6CUUqf4XCLws9uICvbXp4uVUsrNY4lARF4XkXQRqXH6SRHpLyJlIlL1M+AeEB3qJEOfLlbqvDS2amRfdSHXyZN3BG8CI2sqICJ24Bngaw/GcRZrmAm9I1CqtpxOJ8ePH9dk0MAZYzh+/Ph5P2TmsV5DxpgVIpJ4jmIPAJ8A/T0VRwWXC/IzICiK6NAAdh67+MeylfIV8fHxpKWlkZGR4e1Q1Dk4nU7i4+PPaxuvdR8VkTjgBmA450gEIjIVmArQunXrCzvgpo9h3lS4fy0x7hFIXS6DzaaT2Ct1Lg6Hg7Zt23o7DOUh3mwsfg54yBjjOldBY8wsY0yyMSY5Ojr6wo4W7s6Q2QeJDg2gzGU4WVByYftSSqkmxJsPlCUDH7oHh2oOjBaRMmPMZx45WkUiSCMm1Opfm5FXTFRIQA0bKaVU0+e1OwJjTFtjTKIxJhGYC/zSY0kAIKwViA2y00hsHgRASlq2xw6nlFKNhSe7j34ArAI6i0iaiEwRkXtF5F5PHbNGdgeExkJ2GkmxYcRHBrJw0xGvhKKUUg2JJ3sNTTiPspM9FcdpwuMh6wAiwugesbzx731kF5QSHuSol8MrpVRD5FtPFofHQ3YaAKN7xFJabli8rfqxy5VSyhf4XiLIOQQuF73iw4mL0OohpZTysUSQAOUlkJ/hrh5qycpdGWQXlno7MqWU8hrfSwRwVvXQN1u1ekgp5bt8LBGcepbgAAC9EyK0ekgp5fN8NBFYdwQiwqjuLVm5K5OcIq0eUkr5Jt9KBM5w8A+tSAQA1/ZqRUm5i+e/2eXFwJRSynt8KxGIQETCaYmgd0IEd17Shtnf7eOTdWk1bKyUUk2TbyUCqHiorLI/XZvEJe2ieGTeJjYczPJSYEop5R2+mQiyT//l77DbmDmxLzGhAUx9ey2Hswq9FJxSStU/30wEhSegJP+0xc2C/XntzmQKSsq56eXv2XFUJ65RSvkGH0wEp54lOHTWqi4tw/joF4ModxnGvfI9q/Ycr+fglFKq/vlwIjhY5epurcKZ96vBtAhzcufrq7n//fXMXLabZdvTKS4rr8dAlVKqfnhzYhrvqDRTWXXiIgL55N5LeeKLLazed4J/pVgPnA1IbMbbUwbgdNjrI1KllKoXvpcIQmMrJqipSXiQg3+M7w1ATlEpC1KO8Oi8TfzqvfW8cns/HHbfu5lSSjVNvvdtZveD0FbnTASVhTkdTBjQmr+M7c6S7en8YW4KLpfxYJBKKVV/fO+OAKrsQlobtw9qQ1Z+CX9fvJNjOUVMGtSGEV1jCPDTqiKlVOPlm4kgIgHS1lzQpvdf0YFAfzuzv9vHL99bT2SQgweu6MjPL2tbx0EqpVT98OScxa+LSLqIbK5m/UQRSRGRTSLyvYj08lQsZwmPt7qPulznvamIcPeQdnz30BW8eVd/useF85d/bWX64p0Yo9VFSqnGx5NtBG8CI2tYvw8YaozpAfwVmOXBWE4XHg+uUsi78HkI7DZhWOcY3rxrADf3i2fGkl08/dV2TQZKqUbHk5PXrxCRxBrWf1/p4w9AvKdiOUt4a+vfzB0QFntRu7LbhGdu6kmAw8Y/v92Lw2bj9z/rXAdBKqVU/WgovYamAF9Wt1JEporIWhFZm5GRcfFHa3OpNST1mtkXvy/AZhP+OrY7N/aJ45Vv97D/eP65N1JKqQbC64lARIZjJYKHqitjjJlljEk2xiRHR0df/EEDQiB5Cmz7Ao7vufj9YbUdPDSqC3ab8JzObaCUakS8mghEpCfwGjDWGFO/A/sM/AXYHbBqZp3tskWYk8mXJvLZhkPsPKaD1imlGgevJQIRaQ18CtxujNlZ7wGEtoSe42HDe5CfWWe7vXdoe4L9/Zj+df2fklJKXQhPdh/9AFgFdBaRNBGZIiL3isi97iKPAVHASyKyQUTWeiqWal36AJQVwepX62yXkcH+TLmsLV9tOcqmtOw6269SSnmKNLbujsnJyWbt2jrMGe/fCgd/hF9vsBqQ60BuUSlD/ncZ/VpHMnty/zrZp1JKXQwRWWeMSa5qndcbi73ust9A4UmY3g2++DUcWn/Ruwx1Ori1f2u+3ZlBdmFpHQSplFKeo4mg9SCYshiSxsDGj+DV4bDi/y56t1clxVDmMqzYWQfdXZVSyoM0EQAk9IfrX4Lf74Du42Dpf8OWzy5ql70TImkW7M/S7el1FKRSSnmGJoLKnOFWQkgYCPPuhcM/XfCurCEoolm2I52y8vMf00gppeqLJoIz+QXA+PcguDl8MAHSt1/wrkZ0aUFWQSk/HcyqwwCVUqpuaSKoSkg0TPgQSvLhpYHw7jjY/c15j1Z6eafm+NmEb7Zd+OB2SinlaZoIqtOyOzywDoY9CkdT4N2b4IU+sPxpOJlaq12EOh0MbNeMpdu0nUAp1XBpIqhJSAwMewh+sxlufBUi2liJ4Ple8NZ1sGUelJXUuIsrurRgV3oeB44X1FPQSil1fjQR1IafP/S8Be6cD7/ZBMP/BCdS4ePJ8I8kWPw4ZO6uctMru8YAsGS7Vg8ppRomTQTnKyIBhk6znkSeOBfi+8P3L8CL/eD1UbBn6WnF20QF0z46mCVaPaSUaqA0EVwomx06XgUTPoDfboUrn4CcQ1ZPo2NbTis6qnss3+/JZHd6nldCVUqpmmgiqAuhLeGy/4K7l4AzAubcCcX/+dK/a3AiToedGUt0ngKlVMOjiaAuhUTDTa/BiT2w4LfgHtAvKiSAOy5J5IuUw+xO13kKlFINiyaCutZ2CAx7BFI+gp/eqVg89fJ2BDrsPL+k6kZlpZTyFk0EnjDkd9B2KHz1KORZjcTNgv2589JE/pVyWGcvU0o1KJoIPMFmh2v/YU16s/S/KxZPHdKOIIed57WtQCnVgGgi8JSo9ta8yOvfhiMpgDV72c8va8uClCN8tfmIlwNUSimLJ6eqfF1E0kVkczXrRURmiMhuEUkRkb6eisVrLp8GgZGw6NGKhuP7r+hAr/hwpn2cwr7MfC8HqJRSnr0jeBMYWcP6UUBH92sq8LIHY/GOwAgY/iikroTtCwAI8LMzc2Jf7HbhvnfXUVhS7uUglVK+zmOJwBizAjhRQ5GxwNvG8gMQISKxnorHa/rdBdFdYNEj1pSYQHxkEM+N782OY7n88bNNNLZ5o5VSTYs32wjigIOVPqe5l51FRKaKyFoRWZuR0cimfrT7wZgXIOcIfHJPxVDWwzrH8OAVHfl0/SH+uWKvl4NUSvmyRtFYbIyZZYxJNsYkR0dHezuc85cwAEY9DbsXw/K/VSz+9YiOXNerFU9/uZ0vNh72YoBKKV/mzURwCEio9DnevaxpSp4CvSfBiv+taC+w2YT/G9eT/omR/G7ORlbvq6kmTSmlPMObiWA+cIe799AgINsY03T7VIrANX+HVn1g7s/h+xfBVY7TYWfW7cnERwZyz9tr2X9cexIppeqXJ7uPfgCsAjqLSJqITBGRe0XkXneRhcBeYDfwKvBLT8XSYDiccNscaDccvv4jzL4a0rcRGezPG3f1RwSmvr2O/OIyb0eqlPIh0th6rCQnJ5u1a9d6O4yLYwxs/gQWToPiHOg3GS7/AyuP2rjz9dWM6hHLixP6ICLejlQp1USIyDpjTHJV6xpFY3GTIwI9xsH9a6DvnbDuTZjRhyFpr/GHqzuyIOUIs7QnkVKqnmgi8Kbg5nDtdPjVamuSm2+f5hcFsxjdvQXPfLWd73ZlejtCpZQP0ETQEES1h1vegkvuR9a8ynMJK+kQE8IDH6wn7aROeq+U8qxaJQIRCRYRm/t9JxEZIyIOz4bmg676K3S7Af9lT/DOgIOUlRvue3c9RaU6DIVSynNqe0ewAnCKSBzwNXA71lhCqi7ZbHD9K9BmMC2W/hdvDznBpkPZPPb5Zh2GQinlMbVNBGKMKQBuBF4yxtwMdPNcWD7M4YRb34MW3ejz/f282HMvc9am8fRX23G5NBkopeperROBiFwCTAQWuJfZPROSIjAS7pgPCQO5Zuef+UeHjfzz27387uONlJS5vB2dUqqJqW0i+A3wCDDPGLNFRNoByzwXlsIZBhPnIh1GcEPaMyxI/IhlP21nyltr9IEzpVSdOu8HytyNxiHGmBzPhFSzJvFA2fkoK4Glf4VVMylyhPGn/PE4+t7G327q5e3IlFKNyEU/UCYi74tImIgEA5uBrSIyrS6DVNXw84er/wq/WIEzpiPPOl4hZv3zrNzVyIbjVko1WLWtGkpy3wFcD3wJtMXqOaTqS8vu8PNFlPe4lV87PuXzOW+Sp1VESqk6UNtE4HA/N3A9MN8YUwpoF5b6ZrNhH/McRc268ueS6fzzs2+8HZFSqgmobSL4J5AKBAMrRKQN4JU2Ap/nCCRo0vv4+9kZueUPfLtlv7cjUko1crVKBMaYGcaYOGPMaPccw/uB4R6OTVWnWVts416jq+0A/nMmsHaHJgOl1IWrbWNxuIhMPzVvsIj8HevuQHlJQNeR5I96gf6yncD3x7J55y5vh6SUaqRqWzX0OpAL3OJ+5QBveCooVTuhA28n5/p3aCeHCXv/GnZt2+jtkJRSjVBtE0F7Y8zjxpi97teTQDtPBqZqp1nva8i55VPCKKDFR6M4tGa+t0NSSjUytU0EhSJy2akPIjIYKDzXRiIyUkR2iMhuEXm4ivWtRWSZiPwkIikiMrr2oatTWiRdRu4dizlKNLEL7uDkV3+zZkFTSqlaqG0iuBeYKSKpIpIKvAj8oqYNRMQOzARGAUnABBFJOqPYn4A5xpg+wK3AS+cRu6okoV1X5O7FLJLBRP7wNAXv3wGlRd4OSynVCNS219BGY0wvoCfQ0/3FfcU5NhsA7HZXJZUAHwJjz9w1EOZ+Hw4crnXk6iwd42Noffd7/IOJBO2aj+vtMVBwwtthKaUauPOaocwYk1NpjKHfnqN4HHCw0uc097LKngAmiUgasBB4oKodicjUUz2WMjJ0aIWadIuLoMtNf+ZXJQ/iSvsJXrsSTuj8x0qp6l3MVJVSB8efALxpjIkHRgPvnJoJrTJjzCxjTLIxJjk6OroODtu0jeoRi7P3OG4reZSy/BMw+2o4oj2KlFJVu5hEcK7WyENAQqXP8e5llU0B5gAYY1YBTqD5RcSk3B4fk8Sh0F783PZXXPYAePNa2LfS22EppRqgGhOBiOSKSE4Vr1yg1Tn2vQboKCJtRcQfqzH4zL6NB4AR7mN1xUoEWvdTB8KcDqbf0ouVWc14ptXzENYK3r0Jtmr3UqXU6WpMBMaYUGNMWBWvUGOM3zm2LQPuBxYB27B6B20Rkb+IyBh3sd8B94jIRuADYLLRyXnrzMB2Udw7tD3/3FDM4kFvQmwvmHMHrH7V26EppRqQ856Yxtt8bmKai1Ra7mLcK6vYl5HHl7/sR9ySB2DHQhj8axjxBNgupnZQKdVYXPTENKrxcthtvHBrH1wGfv3JTsrGvQXJU+Dfz8Pcu6A419shKqW8TBOBD2gdFcRTN3Rn7f6TPL1oN2b0s3Dlk7BtPswaBse2eDtEpZQXaSLwEWN7x3HHJW147bt9/O7jFIoHPQB3zLfuCF4dAT+95+0QlVJeoonAhzw5phu/u6oTn/50iNtnr+ZkzED4xUpI6A+f/xIW/gHKdfpLpXyNJgIfIiI8MKIjz9/amw0Hspj42o8UOZvDpHkw6Few+p/w7o06LIVSPkYTgQ8a2zuOlyf1ZeuRHJ7+cjvY/WDk/8DYmXBgFcy+CvIzvR2mUqqeaCLwUSO6tuDng9vy5vepfLP1mLWwzyS4/TPIToMPJkDpOUcaV0o1AZoIfNhDozqTFBvGtLkbOZbjHrI6cTDcOAvS1sC8X4DL5d0glVIep4nAhwX42Xnhtj4Ulbp48IOfKC4rt1YkjYWr/wpbP4ev/wiucu8GqpTyKE0EPq59dAhP39SDH/ed4MEPfqKs3H0HcMn9MGAq/PAS/PNy2PutdwNVSnmMJgLF2N5xPHFdEou2HOMPn6TgchkQgVH/Cze/BcU58PYY+HCiPomsVBOkiUABMHlwW+sZg/WH+Mu/tloLRaDb9fCrNTDiMdjxpTWCqSYDpZoUTQSqwv1XdGDKZVZPovkbK80a6nDCkN/BzW9A2lpNBko1MZoIVAUR4ZFRXejbOoI/frqJgycKTi+QNPb0ZJB1sOodKaUaFU0E6jR+dhvP39oHgN98tOE/jcenJI2Fca9bU1++2B+W/Q1KCqrYk1KqsdBEoM6S0CyI/76hO+v2n2TG0t1nF+h2Pdy/BjqPgm+fthJCms4RoVRjpYlAVWls7zhu7BvHjCW7ePPf+84uENHaqia660triIo3r4XtC+s/UKXURfNoIhCRkSKyQ0R2i8jD1ZS5RUS2isgWEXnfk/Go8/M/N/TgqqQWPPHFVqYv3kmVs9m1uRSmLIaYLvDRRFgzu/4DVUpdFI8lAhGxAzOBUUASMEFEks4o0xF4BBhsjOkG/MZT8ajz53TYeXliX8b1i2fGkl386bPNFJVW8ZRxSAxMXgAdroQFv4XZV8PGD6G0qP6DVkqdN0/eEQwAdhtj9hpjSoAPgbFnlLkHmGmMOQlgjEn3YDzqAvjZbfzfuJ784vJ2vPfjAa6c/i1fbT5y9t2BfzDc+gH87G/WyKXzfgHTu8Cuxd4JXClVa55MBHFA5f6Fae5llXUCOonIv0XkBxEZ6cF41AUSER4Z3ZX37x5IsL8f9767nttnryav+IxJbOx+cMkv4YF11uxnYfEw5044kuKdwJVSteLtxmI/oCMwDJgAvCoiEWcWEpGpIrJWRNZmZGTUc4jqlEs7NGfBg5fxxHVJ/HtPJs8u2lF1QRFoNxQmfgyBEfD+eMg5XHVZpZTXeTIRHAISKn2Ody+rLA2Yb4wpNcbsA3ZiJYbTGGNmGWOSjTHJ0dHRHgtYnZuf3cbkwW2ZNLANb69KJSUtq/rCYbFw2xxrrKL3x0NxXr3FqZSqPU8mgjVARxFpKyL+wK3A/DPKfIZ1N4CINMeqKtrrwZhUHZk2sjNRIQE8Om/T2Q+dVdayuzVw3bHN8OZofRpZqQbIY4nAGFMG3A8sArYBc4wxW0TkLyIyxl1sEXBcRLYCy4BpxpjjnopJ1Z0wp4PHr0ti86Ec3l61v+bCHa+0GpJP7INZwyD1u3qJUSlVO1Jl3/AGLEHwEgAAABhXSURBVDk52axdq0+xNgTGGO56cw1r9p1g4a+H0CYquOYNMndZU2Ce3AeXT4NLHwT/oPoJVikfJyLrjDHJVa3zdmOxasREhL+O7Y7Dz8adr68mM6+45g2ad4R7lkLS9bD8b/BiMmz8SKfDVMrLNBGoi5LQLIjXJ/fnaE4Rd72x5uwupWdyhsG42dbQFMHRMG8qvHIZpMyB8nNsq5TyCE0E6qL1bR3JSxP7svVIDve+s67qp4/P1OZSuGcZ3PgqmHL49B6Y0cdKCEqpeqWJQNWJK7q04JmbevLd7kyufeE7fjpw8twb2WzQ8xa4bxVM+BBCoq2EMP9BHZ5CqXqkiUDVmXH94nnr5wMoKC7jppe/56kFW2t3d2CzWUNa//xruOy3sP4teP1qq5eRUsrjNBGoOjW0UzSL/utybh3QmldX7uO3czbgctWyZ5rdD6583N3VNBVmDoAFv4fsM59DVErVJU0Eqs6FOh38zw09+OPorizcdJS/L65mKIrqdBkN9/0bet8G696AGb1h/gNwcA00su7OSjUGft4OQDVddw9py97MPGYu20Pb5iGM6xdf+40jEuC6562qou+mW91M178NUR2gxy3Qfji06mvdRSilLoo+UKY8qrTcxeQ3VrN63wlemNCXkd1bXtiOinJg6+ew4X048L21zD8UOoyAoX+AFt3qLmilmqCaHijTRKA8LruglImzf2DzoRzG9YvnseuSCHM6LnyH+cchdQXs/Ra2fGoliV63wvBHrSk0lVJn0USgvK6kzMULS3fx0vI9xIQG8NDILozuEYu/30U2UxWcgO/+AT/+E4wLeo6HSx+wps5USlXQRKAajI0Hs/jD3BR2HMslOjSASQPb0DU2lOzCUnKKyri0fRRdY8POf8fZafDv52H9O1BWCB2ugqQx1r9hsXV/Iko1MpoIVIPichlW7Mrgze9TWb7j9ImGQgP8+PSXl9KxReiF7Tz/OKx5Fda9BbnuyXBa9LBGQO1wFSQMAPtFVEsp1UhpIlAN1sETBWQXlhLmdFBcVs6EV38k0N/GZ78cTFRIwIXv2BhI3wq7voZd38DBH8BVBgFhkHgZtB0K7YZBdGdrRjWlmjhNBKrR+OnAScbP+oFe8eG8e/dAAvzsdbPjomyrcXn3N7DvWziZai2P62e1KXS5TruiqiZNE4FqVOZvPMyDH/zE1Ukt+N9xPYkI8q/7g5zcDzu/gh9fgRN7IaIN9JtsNTaHx9X98ZTyMk0EqtGZ/d0+/rZwGxFB/jx1Q3d+1u0Cnz84F1c57FgIq15yP58g0G4oJI2F9iMgso1njqtUPdNEoBqlLYezmfZxCluP5DC0UzRXJbVgaKdoEpp5aFaz43sg5SPrdarqKKojtB4ELXtCyx7Qqjc4Aj1zfKU8yGuJQERGAs8DduA1Y8zT1ZS7CZgL9DfG1Pgtr4nAt5SWu5i1Yi/v/3iAQ1mFAPRKiOD58b1JbH6OqTEvlDHWtJp7lsDuJXB4PRS4p9IOCLeGzu57B8T29MzxlfIAryQCEbEDO4GrgDRgDTDBGLP1jHKhwALAH7hfE4GqijGGvZn5LN+RwQtLd1HuMky/pTdXJbWoj4ND7hE4vAG2zLOGuigvhphu0PU66HottOiuvY9Ug+atRHAJ8IQx5mfuz48AGGP+dka554DFwDTg95oI1LkcPFHAL99bz6ZD2dw3rD2/u6oTfvZ6HEi38CSkfGwlhQOrAAPBMVbVUcseENfX6prqDK+/mJQ6h5oSgSf7y8UBByt9TgMGnhFYXyDBGLNARKZVtyMRmQpMBWjdWseS8XUJzYL4+N5LePKLLby8fA/rUk8yY0IfWoY76yeAwEgYONV65WVYjc0HfoBjm2DVTHCVgtittoUOI6xnFmJ7a/dU1WB58o5gHDDSGHO3+/PtwEBjzP3uzzZgKTDZGJMqIsvROwJ1nub9lMYf523G6bDz91t6MbxzjHcDKiuBQ+tg92LYtRiOpljL/UMhoT9Ed4XoTla1Uqs+mhxUvWmQVUMiEg7sAfLcm7QETgBjakoGmgjUmXan53H/++vZfjSXG/vE8cjorkSHXsRTyXUpPxNSV8K+lZC2xmqELrMavQmMhI4/g84jraqkwEhvRqqaOG8lAj+sxuIRwCGsxuLbjDFbqim/HL0jUBeoqLScF5fu5p8r9hDosDPtZ50Z37/1xY9uWtdcLsg+aPVE2vEV7FpktTmIzZpop/1waHMpxCWD8wIG31OqGt7sPjoaeA6r++jrxpinROQvwFpjzPwzyi5HE4G6SLvT8/jzZ5tZtfc4MaEBTB6cyMQBbQgPaqADzZWXWXcKe5fBnqVWtZJxAQIxSVYX1ZiuVlVSdGcIj9feSeqC6ANlyqcYY1ixK5PXVu5l5a5Mgvzt3H5JG6YOaXdxA9nVh6IcOLQWDq62Xulbra6rpziCoXkHa0iMsFbWKzT2P6/wOH3gTVVJE4HyWduO5PDy8j18kXIYp5+dOy5pwy+HdWi4dwhVKTgB6dsgcwdk7ITMndb8CzmHoST37PJhcdCsHUS1h+adoXknCAiF/AwoyAS7v9WLKboz2OpoUD/V4GkiUD5vd3oeLy7dxfyNh4kM8ufhUV24qW88Nlsjr2YpyoHco9ZdQ+4RyDpgDaJ3fA8c32W1P1THEWwNmZEwABIGWr2YgmPA1sDaVVSd0ESglNuWw9n8+bPNrD+QRXKbSB6/rhs94pvog1/GWENjZOyA0kIIbm69SvLh8E/WK20NHNlozdUAYPOzkkFkInQeZQ2+pwPvNQmaCJSqxOUyzF2fxjNfbud4fgk39Ilj2s860yrCR+vWSwutpHB0M+Qdte4wjm76zzMQLXtCi27QrL1V3RTdxfrXr1J7izG+1YhdVgJpq60qu8KT1is/E/LTIS/dqs4rL4byUkCstpuI1lbbTnRn69WsvTVbnnFZ+3RGgMNzD0VqIlCqCjlFpby8fA+zv9uHAJMHJ3Lv5e2JDPbA/AeN0Yl9sPUza+C943v+M/UnWE9OR7S2vuiKsq22CrGDn9NqrI7qYA210aqPlTTC4iA4un7bJIyx4k5dYTW852dCca71KiuEsmLr5ee0uuoGhIJ/CASEWA8ABkVaDfAhLawkl59pvY5shNTvoDT/P8c6VT6khfUKjLT26xdgDXWefdCqtjuZCsU51cfsHwJBzaz35WVgyq2eYjFdrV5kiZdBbK8L+nNoIlCqBmknC/j71zv5bMMhQvz9uOfydtw1OJFQZyNqUK4PJfnWF2vmTsjYbrVF+Dmt6T8DQq0vrbJi64s2YzscSfnPw3NgVTsFRUFgM+vLzuZnVUmVl1jPUTiCwD/Y/Qqx9ili/bouPGnt2xlmjeFk97cav/OOQcFJKC2w1pcXW/sSu/X+1KixwTFWDytnmPWl7R9kfUnb/a3tirKtL+jiPOs8S/KsL/3y4jP+CGI1xLcfDu2vsGa4C2wGfrX88WCMdceVsR1O7rPuBsRm/VuYZcVbcMIqa/ez1p3cb9155KfDkN/BiMcu6PJpIlCqFnYczeXvX+/g663HCA3w47aBrZk8OJHYcB+tMrpY5WVW0sg6ADnuXk75Gf/5YneVgc1hfeEZF5QUWNVUJXnWqzjXWh7YzP0LO8BaVpRl3YkEN7d+fQdFWXchfoH/qWpxlVtJJK4vJF5u3ZWcb9WVMdaxco9an4OauxOYl3pa5WdaMYVEX9DmmgiUOg8paVnMWrGXhZuOYBPhii4xXNurFSO6xBAcoGMD1Stfa3vwIE0ESl2AgycKeOv7VOZvPEx6bjEBfjauSmrBrf1bc2n7qMbf9VT5FE0ESl0El8uwdv9Jvth4mPkbD5NdWEpCs0AmDGjNbQNaExGkjcuq4dNEoFQdKSotZ9GWo3y4+iCr9h4n0GHn5uR47rgkkQ4xId4OT6lqaSJQygO2H81h9sp9fL7hMCXlLrrGhnFtz1jG9GpFQrMgb4en1Gk0ESjlQem5Rfxr4xH+lXKY9QeyEIHhnWO489JEhnRorm0JqkHQRKBUPUk7WcCcNQd5f/UBMvNKiIsI5JL2UQxIbMagdlG0jtI7BeUdmgiUqmfFZeUs3HSELzcdZe3+k5zILwGgU4sQftatJT/r1pJurcIQ7Rqp6okmAqW8yBjDnow8VuzM5OutR1m97wQuAwnNAhndPZbRPWLpEReuVUjKozQRKNWAnMgv4Zutx1iw6Qj/3p1JmcsQHRrA8M7RDO8cQ/e4cOIiAjUxqDrlzakqRwLPY01V+Zox5ukz1v8WuBsoAzKAnxtj9te0T00EqinJKihhybZ0lu5IZ8XODHKLrOGgg/3tdGwRyiXtoxjeOYa+rSPws+s8AerCeWvyejvW5PVXAWlYk9dPMMZsrVRmOPCjMaZARO4Dhhljxte0X00EqqkqLXex6VA2O47msuNoLlsP57D+wEnKXIZQpx/dW4XTuWUonVqEEhvuJDLYn6hgf1qGO3FoklDnUFMi8OTAKQOA3caYve4gPgTGAhWJwBizrFL5H4BJHoxHqQbNYbfRt3UkfVtHVizLKSrl37syWbErk21Hcpiz9iAFJeWnbedvt9GxRQhJsWF0iAmhTVQwic2DCHTYySsuI6+oDKfDTmJUcOOaolPVG08mgjjgYKXPacDAGspPAb6saoWITAWmArRu3bqu4lOqwQtzOhjVI5ZRPWIBa7iLw9mFpOcWczK/hON5JezJyGPrkRyW7Ujn43VpNe4vMshB66hgYsOcxEY4CXU6yCsqI6+4lCB/PyYObE3HFqH1cWqqAWkQQymKyCQgGRha1XpjzCxgFlhVQ/UYmlINis0mxEcGER9Z9fMI2YWlHDheQOrxfIrLXIQE+BES4Ed+SRn7j+ezL7OAtJMF7M7IY+WuDPJLyivKnCwo4c3vUxnRJYafX9aWfm0icTp0cntf4MlEcAhIqPQ53r3sNCJyJfBHYKgx5sxZIJRS5yE80EGP+PBazcNsjMEYKnonncgv4e1Vqby9aj8TX/sRP5vQqUUoSa3CiAh0EBTgR0iAnYggq20i1OngaE4RB08UkJ5TxIiuLRjSsbk+G9EIebKx2A+rsXgEVgJYA9xmjNlSqUwfYC4w0hizqzb71cZipTyrsKSclbsySEnLZmNaFjuP5ZJXVEb+GW0TlQX42Sguc9E7IYIHrujAsM4x2LX7a4Pize6jo4HnsLqPvm6MeUpE/gKsNcbMF5FvgB7AEfcmB4wxY2rapyYCpbzD5TLkl5SRVVDK8fwScgpLiQkLICEyCD+7MHddGi8t28OhrEJCA/zo0yaS5DaRtIkKIiLIn8ggB81DAogODdBeTl6gD5QppepFabmLrzYfZdXe46xLPcnO9FzO/IoRgWZB/sRGOImPCCIuMpDWzYJIbB5M26hg4iID9W7CA7zVfVQp5WMcdhvX9WrFdb1aAZBbVMqxnGKyCko4kV9CZl4J6blFHMsp5kh2IXsy8vh2ZwaFpf+pdvK322gTFUS76GA6xITQpWUYXWPDSIwK0ofqPEQTgVLKY0KdDkKdNT+7YIwhI6+YfRn5pB7PZ29mPnsz8tmdnsc329Ipd1m3FE6Hja6xYfSIC6dTi1Cigv0JD3QQFuggzOkgxGn1fvL3q59kUVxWTm5RWcUdj7+fjTCnX6NsLNdEoJTyKhEhJtRJTKiTge2iTltXXFbO7vQ8th/JZeuRHDYdyuaTdWnVNlzbBNpFh9C9VRhJrcJoExVMfGQg8RFBhAXW7ks6q6CEtaknST2ez9HsIo7mFJFXXEa5y1Ba7iKnsIxjOUUcd48oW5m/3UZUiPW0d5eWoXRuEUrnlmF0ahFCVEjAhf2B6oG2ESilGhWXy3Ast4isglKyC0vJKiglv7iM3CKrEXvbkRy2HM7hSHbRads5HTZ3wgmgeUgAzUP9iQoOoNxlyCsuI7uwlC2Hs9l5LO+0bVqGOQkLdOBnE/xsNoID7MRGBNIyzElEkAMBEKG4tJzMvBIycos5lFXA9qO5ZBWUVuwrKtifDjEhFa/20SHERVr7CQ6o/jd5YUk5+0/kk5pZQHxkIN3jzt01uCraRqCUajJsNiE2PJDY8MAay2UVlHDwRCFpJwtIO1nIsZwi0nOLSc8tYndGHj/uK+ZkQSk2saqwQgL8aB8TwpherRjQNorOLUJrfRdRFWMM6bnFbDuSw+70PHan57HzWC5fbDxMjntwwVNCA/wI9LcT4LDhsNusu48yF0Vlroq5LADuvqztBSeCmmgiUEo1SRFB/kQE+df4cF25y2ATPFKvLyK0CHPSIszJsM4xFctPtYnszbCqno5kF3Esp4jisnKKS10Ul7vwswkOuw1/PxuxYU7auHtUJTb3zAx3mgiUUj7LG91UK7eJNBTaF0sppXycJgKllPJxmgiUUsrHaSJQSikfp4lAKaV8nCYCpZTycZoIlFLKx2kiUEopH9foxhoSkQxg/wVu3hzIrMNwGgtfPG9fPGfwzfP2xXOG8z/vNsaY6KpWNLpEcDFEZG11gy41Zb543r54zuCb5+2L5wx1e95aNaSUUj5OE4FSSvk4X0sEs7wdgJf44nn74jmDb563L54z1OF5+1QbgVJKqbP52h2BUkqpM2giUEopH+cziUBERorIDhHZLSIPezseTxCRBBFZJiJbRWSLiPzavbyZiCwWkV3ufyO9HasniIhdRH4SkX+5P7cVkR/d1/wjEfH3dox1SUQiRGSuiGwXkW0icokvXGsR+S/3/+/NIvKBiDib4rUWkddFJF1ENldaVuX1FcsM9/mniEjf8zmWTyQCEbEDM4FRQBIwQUSSvBuVR5QBvzPGJAGDgF+5z/NhYIkxpiOwxP25Kfo1sK3S52eAfxhjOgAngSleicpznge+MsZ0AXphnXuTvtYiEgc8CCQbY7oDduBWmua1fhMYecay6q7vKKCj+zUVePl8DuQTiQAYAOw2xuw1xpQAHwJjvRxTnTPGHDHGrHe/z8X6YojDOte33MXeAq73ToSeIyLxwDXAa+7PAlwBzHUXaVLnLSLhwOXAbABjTIkxJgsfuNZYU+wGiogfEAQcoQlea2PMCuDEGYuru75jgbeN5QcgQkRia3ssX0kEccDBSp/T3MuaLBFJBPoAPwItjDFH3KuOAi28FJYnPQf8AXC5P0cBWcaYMvfnpnbN2wIZwBvu6rDXRCSYJn6tjTGHgGeBA1gJIBtYR9O+1pVVd30v6jvOVxKBTxGREOAT4DfGmJzK64zVX7hJ9RkWkWuBdGPMOm/HUo/8gL7Ay8aYPkA+Z1QDNdFrHYn167ct0AoI5uzqE59Ql9fXVxLBISCh0ud497ImR0QcWEngPWPMp+7Fx07dJrr/TfdWfB4yGBgjIqlY1X5XYNWfR7irD6DpXfM0IM0Y86P781ysxNDUr/WVwD5jTIYxphT4FOv6N+VrXVl11/eivuN8JRGsATq6exb4YzUuzfdyTHXOXS8+G9hmjJleadV84E73+zuBz+s7Nk8yxjxijIk3xiRiXdulxpiJwDJgnLtYkzpvY8xR4KCIdHYvGgFspYlfa6wqoUEiEuT+/37qvJvstT5Dddd3PnCHu/fQICC7UhXSuRljfOIFjAZ2AnuAP3o7Hg+d42VYt4opwAb3azRWffkSYBfwDdDM27F68G8wDPiX+307YDWwG/gYCPB2fHV8rr2Bte7r/RkQ6QvXGngS2A5sBt4BApritQY+wGoHKcW6A5xS3fUFBKtn5B5gE1avqlofS4eYUEopH+crVUNKKaWqoYlAKaV8nCYCpZTycZoIlFLKx2kiUEopH6eJQKkziEi5iGyo9KqzgdtEJLHyaJJKNQR+5y6ilM8pNMb09nYQStUXvSNQqpZEJFVE/ldENonIahHp4F6eKCJL3ePALxGR1u7lLURknohsdL8ude/KLiKvusfU/1pEAr12UkqhiUCpqgSeUTU0vtK6bGNMD+BFrBFPAV4A3jLG9ATeA2a4l88AvjXG9MIaB2iLe3lHYKYxphuQBdzk4fNRqkb6ZLFSZxCRPGNMSBXLU4ErjDF73YP7HTXGRIlIJhBrjCl1Lz9ijGkuIhlAvDGmuNI+EoHFxppYBBF5CHAYY/7b82emVNX0jkCp82OqeX8+iiu9L0fb6pSXaSJQ6vyMr/TvKvf777FGPQWYCKx0v18C3AcV8ymH11eQSp0P/SWi1NkCRWRDpc9fGWNOdSGNFJEUrF/1E9zLHsCaKWwa1qxhd7mX/xqYJSJTsH7534c1mqRSDYq2EShVS+42gmRjTKa3Y1GqLmnVkFJK+Ti9I1BKKR+ndwRKKeXjNBEopZSP00SglFI+ThOBUkr5OE0ESinl4/4fbhDX3vJRh9QAAAAASUVORK5CYII=\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YY7FWYq0dnDS"
      },
      "source": [
        "# with open('dictionary.pickle', 'wb') as handle:\n",
        "#     pickle.dump(dictionary, handle, protocol=pickle.HIGHEST_PROTOCOL)\n",
        "\n",
        "# with open('reverse_dictionary.pickle', 'wb') as handle:\n",
        "#     pickle.dump(reverse_dictionary, handle, protocol=pickle.HIGHEST_PROTOCOL)"
      ],
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6Bz93atBdgpM"
      },
      "source": [
        "with open(saved_model_path + 'dictionary.pickle', 'rb') as handle:\n",
        "    dictionary = pickle.load(handle)\n",
        "\n",
        "with open(saved_model_path + 'reverse_dictionary.pickle', 'rb') as handle:\n",
        "    reverse_dictionary = pickle.load(handle)"
      ],
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Kd4xzYhId1_L",
        "outputId": "47360726-ad4b-4014-c232-b0a047261676"
      },
      "source": [
        "print(dictionary)"
      ],
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'[': 0, '“': 1, 'f': 2, '*': 3, '#': 4, 'ц': 5, '?': 6, '”': 7, \"'\": 8, ',': 9, '»': 10, '\"': 11, '9': 12, '‑': 13, '@': 14, '<': 15, 'с': 16, 'c': 17, 'о': 18, 'л': 19, 'п': 20, 'б': 21, 'e': 22, 'ш': 23, 'і': 24, '—': 25, 'ж': 26, ';': 27, 'е': 28, '|': 29, '̀': 30, 'r': 31, 'h': 32, 'o': 33, '1': 34, '5': 35, '3': 36, 's': 37, 'у': 38, '’': 39, 'g': 40, '―': 41, 'τ': 42, '!': 43, '>': 44, '{': 45, 'j': 46, 'ъ': 47, 'х': 48, '6': 49, 'ѭ': 50, 'ῳ': 51, 'a': 52, 'г': 53, 'к': 54, 'x': 55, ':': 56, 'ы': 57, 't': 58, 'н': 59, '́': 60, '4': 61, 'м': 62, 'з': 63, 'ь': 64, 'l': 65, 'k': 66, ']': 67, 'z': 68, 'в': 69, '\\\\': 70, 'ῷ': 71, 'и': 72, 'ό': 73, 'ӏ': 74, '‐': 75, '(': 76, 'щ': 77, 'i': 78, '‘': 79, 'p': 80, 'т': 81, 'а': 82, 'ф': 83, 'd': 84, '.': 85, 'n': 86, '2': 87, '/': 88, 'm': 89, 'ӣ': 90, '8': 91, 'ю': 92, 'ѫ': 93, 'р': 94, '-': 95, '0': 96, '7': 97, 'я': 98, '}': 99, ')': 100, 'γ': 101, 'й': 102, 'ѣ': 103, 'v': 104, '%': 105, 'b': 106, 'ч': 107, 'u': 108, 'д': 109, '<PAD>': 110, '<UNK>': 111, '<GO>': 112, '<END>': 113}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-F9lXSIp-KBJ"
      },
      "source": [
        "def to_seq(text):\n",
        "    # preprocess text for the model\n",
        "    return [dictionary.get(word, dictionary['<UNK>']) for word in text] + [dictionary['<PAD>']]*(sequence_length-len(text))"
      ],
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HWZlV_qw-KBJ",
        "outputId": "6918c16b-415f-4576-f845-055229eeb797"
      },
      "source": [
        "pad = dictionary[\"<PAD>\"] \n",
        "\n",
        "checkpoint = path_to_dataset + '/seq2seq/seq2seq.ckpt'\n",
        "\n",
        "loaded_graph = tf.Graph()\n",
        "with tf.Session(graph=loaded_graph) as sess:\n",
        "    \n",
        "    # load the model\n",
        "    loader = tf.train.import_meta_graph(checkpoint + '.meta')\n",
        "    loader.restore(sess, checkpoint)\n",
        "\n",
        "    input_data = loaded_graph.get_tensor_by_name('inputs:0')\n",
        "    logits = loaded_graph.get_tensor_by_name('predictions:0')\n",
        "    input_sequence_length = loaded_graph.get_tensor_by_name('input_sequence_length:0')\n",
        "    label_sequence_length = loaded_graph.get_tensor_by_name('label_sequence_length:0')\n",
        "   \n",
        "    # words = ['когаго']\n",
        "    # words = ['когато']\n",
        "    # words = ['нещо']\n",
        "    # words = ['срЪдъ']\n",
        "    # words = ['погрешка']\n",
        "    # words = ['турилъ']\n",
        "    words = ['грешка']\n",
        "    # words = ['твърде']\n",
        "\n",
        "    input_sentence = ' '.join(words)\n",
        "    \n",
        "    print()\n",
        "    print('Original Text: %s' % input_sentence)\n",
        "    print('Word Ids: %s' % ([[letter for letter in to_seq(word.lower())] for word in words]))\n",
        "    inputWords = [\" \".join([reverse_dictionary[i] for i in to_seq(word)]) for word in words]\n",
        "    print('Input words: %s' % inputWords)\n",
        "    \n",
        "    print()\n",
        "    print(\"Output:\")\n",
        "    outputs = list()\n",
        "    for word in input_sentence.split(' '):\n",
        "        word_seq = to_seq(word.lower())\n",
        "        answer_logits = sess.run(logits, {input_data: [word_seq] * batch_size, label_sequence_length: [len(word_seq)] * batch_size, input_sequence_length: [len(word_seq)]*batch_size})[0]\n",
        "\n",
        "        \n",
        "        output_word = ''.join([reverse_dictionary[i] for i in answer_logits if i != pad])\n",
        "\n",
        "        print('Word Ids: %s' % ([i for i in answer_logits if i != pad]))\n",
        "        print('Response Word: %s' % (output_word))\n",
        "        outputs.append(output_word)\n",
        "    \n",
        "    print()\n",
        "    print(\"Sentence output: %s\" % (' '.join(outputs)))"
      ],
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:tensorflow:Restoring parameters from /content/gdrive/My Drive/IR/icdar2019/seq2seq/seq2seq.ckpt\n",
            "\n",
            "Original Text: грешка\n",
            "Word Ids: [[53, 94, 28, 23, 54, 82, 110, 110, 110, 110]]\n",
            "Input words: ['г р е ш к а <PAD> <PAD> <PAD> <PAD>']\n",
            "\n",
            "Output:\n",
            "Word Ids: [53, 94, 103, 23, 54, 82]\n",
            "Response Word: грѣшка\n",
            "\n",
            "Sentence output: грѣшка\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oS17oQ_f-KBJ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4f79737d-f6fb-4389-c836-8e48ff3cc874"
      },
      "source": [
        "!zip -r model.zip ./saved"
      ],
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\tzip warning: name not matched: ./saved\n",
            "\n",
            "zip error: Nothing to do! (try: zip -r model.zip . -i ./saved)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "J1wQOW1NKOhn",
        "outputId": "04420d27-8fa4-434e-b565-de883ec8c98c"
      },
      "source": [
        "test_dataset = path_to_dataset + '/correct_sentence.txt'\n",
        "test_dataset_words = path_to_dataset + '/correct_test_single.txt'\n",
        "test_pairs_sentences = create_pairs(test_dataset,start=1)\n",
        "test_pairs_single = create_pairs(test_dataset_words)"
      ],
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Reading lines...\n",
            "Reading lines...\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kEpVkptQKZKm",
        "outputId": "9c1fd5bb-d299-42ad-cdc5-438a68490fc1"
      },
      "source": [
        "hackset = set()\n",
        "for pair in test_pairs_single:\n",
        "  hackset.add(pair[0])\n",
        "\n",
        "print(random.sample(hackset, 10))"
      ],
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['вр^ме,', 'грехъ', 'ежщчостьта', 'георгпевъ', 'твърдо', 'чук', 'з-й', 'кждрп', 'сждъ.', 'подробностите']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WiPv2G1hMII6",
        "outputId": "cd9e4ada-fb75-46be-ef42-4b29819dc519"
      },
      "source": [
        "!pip install Levenshtein\n",
        "from Levenshtein import distance as levenshtein_distance"
      ],
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting Levenshtein\n",
            "  Downloading Levenshtein-0.15.0-cp37-cp37m-manylinux2010_x86_64.whl (110 kB)\n",
            "\u001b[K     |████████████████████████████████| 110 kB 5.2 MB/s \n",
            "\u001b[?25hCollecting rapidfuzz<1.7,>=1.5.1\n",
            "  Downloading rapidfuzz-1.6.2-cp37-cp37m-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_12_x86_64.manylinux2010_x86_64.whl (2.0 MB)\n",
            "\u001b[K     |████████████████████████████████| 2.0 MB 39.0 MB/s \n",
            "\u001b[?25hRequirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from rapidfuzz<1.7,>=1.5.1->Levenshtein) (1.19.5)\n",
            "Installing collected packages: rapidfuzz, Levenshtein\n",
            "Successfully installed Levenshtein-0.15.0 rapidfuzz-1.6.2\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gueMFjOYRR5U"
      },
      "source": [
        "def clean_up(word):\n",
        "  word = re.sub(r'\\n', '', word)\n",
        "  word = word.replace('@', '')\n",
        "  word = word.lower()\n",
        "  return word.strip()"
      ],
      "execution_count": 35,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3eO9m7dMRH_s",
        "outputId": "d30582b5-fc57-4328-d56a-fb645d9f2ede"
      },
      "source": [
        "file_clada = path_to_dataset + '/clada.txt'\n",
        "def parse_clada(file):\n",
        "  clada_set = set()\n",
        "  with open(file, \"r\", encoding=\"utf-16\") as f:\n",
        "    raw_text = f.readlines()\n",
        "\n",
        "  for word in raw_text:\n",
        "    temp = clean_up(word)\n",
        "    if temp not in clada_set:\n",
        "      clada_set.add(temp)\n",
        "\n",
        "  return clada_set\n",
        "\n",
        "clada_set = parse_clada(file_clada)\n",
        "print(random.sample(clada_set, 10))\n",
        "print(len(clada_set))"
      ],
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['хранителката', 'нагърбушвашъ', 'лордската', 'измелилото', 'млеченъ', 'досъбличашъ', 'второразредни', 'невротизиращо', 'душманската', 'додѣващото']\n",
            "1106371\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yvZeKtX_6rJ7",
        "outputId": "901924b9-51ec-48e4-a2e6-98b0c84dd68b"
      },
      "source": [
        "pad = dictionary[\"<PAD>\"]\n",
        "\n",
        "checkpoint = path_to_dataset + '/seq2seq/seq2seq.ckpt'\n",
        "\n",
        "distances0 = []\n",
        "distances1 = []\n",
        "\n",
        "loaded_graph = tf.Graph()\n",
        "with tf.Session(graph=loaded_graph) as sess:\n",
        "    \n",
        "    # load the model\n",
        "    loader = tf.train.import_meta_graph(checkpoint + '.meta')\n",
        "    loader.restore(sess, checkpoint)\n",
        "\n",
        "    input_data = loaded_graph.get_tensor_by_name('inputs:0')\n",
        "    logits = loaded_graph.get_tensor_by_name('predictions:0')\n",
        "    input_sequence_length = loaded_graph.get_tensor_by_name('input_sequence_length:0')\n",
        "    label_sequence_length = loaded_graph.get_tensor_by_name('label_sequence_length:0')\n",
        "    \n",
        "    for pair in test_pairs_single:\n",
        "      input_sentence = clean_up(pair[0])\n",
        "      gs_sentence = clean_up(pair[1])\n",
        "\n",
        "      words = input_sentence.split(' ')\n",
        "      outputs = list()\n",
        "      for word in input_sentence.split(' '):\n",
        "          word_seq = to_seq(word)\n",
        "          answer_logits = sess.run(logits, {input_data: [word_seq] * batch_size, label_sequence_length: [len(word_seq)] * batch_size, input_sequence_length: [len(word_seq)] * batch_size})[0]          \n",
        "          output_word = ''.join([reverse_dictionary[i] for i in answer_logits if i != pad])\n",
        "\n",
        "          outputs.append(output_word if output_word in clada_set else word)\n",
        "\n",
        "      model_sentence_out = ' '.join(outputs)\n",
        "    \n",
        "\n",
        "\n",
        "      levdist0 = levenshtein_distance(input_sentence, gs_sentence) # distance between aligned and GS\n",
        "      levdist1 = levenshtein_distance(model_sentence_out, gs_sentence) # distance between model and GS\n",
        "\n",
        "      distances0.append(levdist0)\n",
        "      distances1.append(levdist1)\n",
        "\n",
        "    print(sum(distances0))\n",
        "    print(sum(distances1))"
      ],
      "execution_count": 45,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:tensorflow:Restoring parameters from /content/gdrive/My Drive/IR/icdar2019/seq2seq/seq2seq.ckpt\n",
            "9325\n",
            "9325\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ves1QaWFVrKn",
        "outputId": "a064ceac-382d-4859-ce3a-6ba514716789"
      },
      "source": [
        "improvement = (sum(distances0) - sum(distances1)) / sum(distances0)\n",
        "print(\"The improvement is {:.3f}%\".format(improvement * 100))"
      ],
      "execution_count": 48,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The improvement is 18.660%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ABxGASOqUvT3"
      },
      "source": [
        "def autocorrect(token):\n",
        "        candidates = self.candidates_edits1(token)\n",
        "\n",
        "        if len(candidates) > 0:\n",
        "            top_candidate = sorted(candidates, key=lambda candidate: self.probability(candidate, self.total))[:1]\n",
        "\n",
        "            return top_candidate[0]\n",
        "\n",
        "        return None"
      ],
      "execution_count": 49,
      "outputs": []
    }
  ]
}